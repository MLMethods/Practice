{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e14ba7",
   "metadata": {},
   "source": [
    "# Распознавание голосовых команд\n",
    "\n",
    "<hr>\n",
    "\n",
    "С.Ю. Папулин (papulin.study@yandex.ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c94e59",
   "metadata": {},
   "source": [
    "### Содержание\n",
    "\n",
    "- [Метод опорных векторов](#Метод-опорных-векторов)\n",
    "- [Распознавание цифр](#Распознавание-цифр)\n",
    "- [Разпознавание голосовых команд](#Разпознавание-голосовых-команд)\n",
    "    - [Предобработка аудио данных](#Предобработка-аудио-данных)\n",
    "    - [Загрузка датасета](#Загрузка-датасета)\n",
    "    - [Оконное преобразование Фурье](#Оконное-преобразование-Фурье)\n",
    "    - [Масштабирование спектрограммы](#Масштабирование-спектрограммы)\n",
    "    - [Обучение и предсказание](#Обучение-и-предсказание)\n",
    "- [Источники](#Источники)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ff732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020d3810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddadf0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d225de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.inspection import DecisionBoundaryDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176dbe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../lib/\")\n",
    "from plot_utils import CPlot, RPlot\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ef1849",
   "metadata": {},
   "source": [
    "## Метод опорных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d9a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=200, noise=0.3, random_state=12345)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845e16e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2, \n",
    "    random_state=12345\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9487747",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLR_MAP = ListedColormap(['blue', 'green'])\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.title('Initial dataset')\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=CLR_MAP)\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4020f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('Linear SVC', LinearSVC()),\n",
    "    ('SVC with Linear Kernel (SVC)', SVC(kernel='linear')),\n",
    "    ('SVC with Poly Kernel', SVC(kernel='poly', degree=4)),\n",
    "    ('SVC with RBF Kernel', SVC(kernel='rbf', gamma='scale'))\n",
    "]\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f'{name}: Accuracy on test = {model.score(X_test, y_test)}')\n",
    "    CPlot.show_train_test_plots(model, X_train, y_train, X_test, y_test, title=name, cmap=CLR_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e5041",
   "metadata": {},
   "source": [
    "## Распознавание цифр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60718500",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219d1f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка исходных данных\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9713499",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_INDX = 3\n",
    "\n",
    "print(\"Features:\\n\", digits[\"images\"][IMAGE_INDX])\n",
    "print(\"Target value:\", digits.target[IMAGE_INDX])\n",
    "\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(digits.images[IMAGE_INDX])\n",
    "plt.axis('off')\n",
    "# plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1287c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование исходных данных\n",
    "# Замечание: \n",
    "#  digits.data уже содержит преобразованные данные\n",
    "X = digits['images'].reshape(-1, 64)\n",
    "y = digits['target']\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcf351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формирование обучающего и тестового подмножеств\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=100)\n",
    "\n",
    "\n",
    "models = [\n",
    "    ('Multinomial Logistic Regression', LogisticRegression(\n",
    "        C=1.0, \n",
    "        multi_class='multinomial', \n",
    "        solver='newton-cg', \n",
    "        max_iter=200, \n",
    "        random_state=12345)\n",
    "    ),\n",
    "    ('SVC with RBF Kernel', SVC(kernel='rbf', gamma='scale'))\n",
    "]\n",
    "\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f'{name}: Accuracy on test = {model.score(X_test, y_test)}')\n",
    "    ConfusionMatrixDisplay.from_predictions(\n",
    "        y_true=y_test,\n",
    "        y_pred=model.predict(X_test)\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3b1586",
   "metadata": {},
   "source": [
    "## Разпознавание голосовых команд"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96861ad5",
   "metadata": {},
   "source": [
    "- Набор данных по [ссылке](http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip) (мини версия ~200MB)\n",
    "- Описание набора данных: [Speech Commands Dataset](https://ai.googleblog.com/2017/08/launching-speech-commands-dataset.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dc5e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Util functions to load and process audio data\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "AUDIO_BASE_DIR = '/home/ubuntu/Downloads/mini_speech_commands/mini_speech_commands/'\n",
    "\n",
    "\n",
    "\n",
    "def pad_audio_data(data, rate):\n",
    "    \"\"\"Add pads to 1sec length (16k samples).\"\"\"\n",
    "    pad_width = rate - data.shape[0]\n",
    "    return np.pad(\n",
    "        array=data, \n",
    "        pad_width=(0, pad_width), \n",
    "        mode='constant', \n",
    "        constant_values=(0, 0)\n",
    "    )\n",
    "\n",
    "    \n",
    "def normalize_audio_amplitude(data):\n",
    "    return data / 32767\n",
    "\n",
    "    \n",
    "def load_audio_data(file_path):\n",
    "    rate, data = wavfile.read(file_path)\n",
    "    data_padded = pad_audio_data(data, rate)\n",
    "    return normalize_audio_amplitude(data_padded)\n",
    "\n",
    "\n",
    "def load_audio_dataset():\n",
    "    dataset_dir = AUDIO_BASE_DIR\n",
    "    targets_dirs = os.listdir(dataset_dir)\n",
    "    targets_dirs.remove('README.md')\n",
    "    n_files = 0\n",
    "    for target_dir in targets_dirs:\n",
    "        full_target_dir = os.path.join(dataset_dir, target_dir)\n",
    "        n_files += len(os.listdir(full_target_dir))\n",
    "    X = np.zeros((n_files, 16000), dtype=np.float16)\n",
    "    y = np.zeros(n_files, dtype=int)\n",
    "    file_list = list()\n",
    "    i = 0\n",
    "    for j in range(len(targets_dirs)):\n",
    "        full_target_dir = os.path.join(dataset_dir, targets_dirs[j])\n",
    "        for file_name in os.listdir(full_target_dir):\n",
    "            full_file_name = os.path.join(full_target_dir, file_name)\n",
    "            X[i] = load_audio_data(full_file_name)\n",
    "            y[i] = j\n",
    "            file_list.append(full_file_name) \n",
    "            i += 1\n",
    "    return X, y, targets_dirs, file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5431ee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(AUDIO_BASE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d1e1cc",
   "metadata": {},
   "source": [
    "### Предобработка аудио данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b860b36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_PATH = f'{AUDIO_BASE_DIR}/left/1b4c9b89_nohash_3.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fddef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio \n",
    "Audio(SAMPLE_PATH, autoplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2334192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read an audio data from the file\n",
    "rate, audio_data = wavfile.read(SAMPLE_PATH)\n",
    "rate, audio_data.shape, audio_data.min(), audio_data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1990ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add zeros to end if data length less than 16k\n",
    "audio_data_padded = pad_audio_data(audio_data, rate)\n",
    "audio_data_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8395eda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize amplitude\n",
    "audio_data_normalized = normalize_audio_amplitude(audio_data_padded)\n",
    "audio_data_normalized.shape, audio_data_normalized.min(), audio_data_normalized.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b5c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = np.arange(audio_data.shape[0])\n",
    "\n",
    "plt.figure(figsize=[12,4])\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Command: Left')\n",
    "plt.plot(n_samples, audio_data)\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.xlim([0, 16000])\n",
    "# plt.ylim([-1, 1])\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Command: Left')\n",
    "plt.plot(n_samples, audio_data_normalized)\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.xlim([0, 16000])\n",
    "# plt.ylim([-1, 1])\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f13e2b",
   "metadata": {},
   "source": [
    "### Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eeb7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка всего датасета\n",
    "X, y, target_names, files = load_audio_dataset()\n",
    "X.shape, y.shape, target_names, len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623209ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество наблюдений по классам\n",
    "list(zip(target_names, *np.unique(y, return_counts=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea53063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_INDEX = 1005\n",
    "target_names[y[DATA_INDEX]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efbf4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[DATA_INDEX].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72476f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio \n",
    "Audio(files[DATA_INDEX], autoplay=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277a9cbf",
   "metadata": {},
   "source": [
    "### Оконное преобразование Фурье"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d97f9c",
   "metadata": {},
   "source": [
    "#### Построение спектрограммы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c12ee3",
   "metadata": {},
   "source": [
    "<!-- ![image](https://docs.exponenta.ru/signal/ref/iscola_stft.png) -->\n",
    "\n",
    "\n",
    "<img src=\"https://docs.exponenta.ru/signal/ref/iscola_stft.png\" width=\"600px\">\n",
    "\n",
    "https://docs.exponenta.ru/signal/ref/stft.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6537f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, time_segments, Zxx = signal.stft(X[DATA_INDEX], window='hann', fs=16e3, nperseg=256, noverlap=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043e4ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zxx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416355e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.abs(Zxx)\n",
    "Z.shape, Z.min(), Z.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c4b8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[14,6])\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(time_segments, freq, Z)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(time_segments, freq, np.log(Z + np.finfo(float).eps))\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86841dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[DATA_INDEX].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ea104",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8,6])\n",
    "\n",
    "time_scale = np.linspace(0.0, 1.0, rate)\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Signal')\n",
    "plt.plot(time_scale, X[DATA_INDEX])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.xlim([0, 1])\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Short Time FFT (Spectrogram)')\n",
    "plt.pcolormesh(time_segments, freq, np.log(Z + np.finfo(float).eps))\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5cae67",
   "metadata": {},
   "source": [
    "#### Спектрограммы для всего набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9cab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование исходных сигналов в спекторграммы\n",
    "X_spectrogram = np.zeros((X.shape[0], *Z.shape))\n",
    "for i in range(X.shape[0]):\n",
    "    _, _, Zxx = signal.stft(X[i], window='hann', fs=16e3, nperseg=256, noverlap=128)\n",
    "    X_spectrogram[i] = np.log(np.abs(Zxx) + np.finfo(float).eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3530dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d9b74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отображение 6 случайных сигналов и их спектограмм\n",
    "\n",
    "cols = 3\n",
    "rows = 4\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "indxs = np.random.randint(0, 8000, (2, 3))\n",
    "indxs_ = np.repeat(indxs, repeats=2, axis=0)\n",
    "\n",
    "plt.figure(figsize=[12,10])\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        plt.subplot(rows, cols, i*cols + j + 1)\n",
    "        if (i*cols + j) // cols % 2 == 0:\n",
    "            plt.title(f'{target_names[y[indxs_[i, j]]]}: {indxs_[i, j]}')\n",
    "            plt.plot(time_scale, X[indxs_[i, j]])\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Amplitude')\n",
    "            plt.xlim([0, 1])\n",
    "            plt.grid()\n",
    "        else:\n",
    "            plt.title(f'{target_names[y[indxs_[i, j]]]}: {indxs_[i, j]}')\n",
    "            plt.pcolormesh(time_segments, freq, X_spectrogram[indxs_[i, j]])\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Frequency')\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2321c86d",
   "metadata": {},
   "source": [
    "### Масштабирование спектрограммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4ebdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize, resize_local_mean, downscale_local_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17146dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resized = np.zeros((X_spectrogram.shape[0], 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898708df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Уменьшаем размер спекторграмм до 32x32\n",
    "for i in range(X_spectrogram.shape[0]):\n",
    "    X_resized[i] = resize_local_mean(X_spectrogram[i], (32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a9c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Short Time FFT (Spectrogram)')\n",
    "plt.pcolormesh(range(32), range(32), X_resized[DATA_INDEX])\n",
    "plt.colorbar()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff8f3a3",
   "metadata": {},
   "source": [
    "### Обучение и предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715a6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формирование вектора признаков: 32x32 -> 1024\n",
    "X_features = X_resized.reshape(X_resized.shape[0], -1)\n",
    "X_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eb7c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27f3ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение и оценка качества на тестовом множестве\n",
    "pipeline = Pipeline([\n",
    "    ('standardizer', StandardScaler()),\n",
    "    ('clf', SVC(kernel='rbf', C=10))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c1f5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true=y_test,\n",
    "    y_pred=pipeline.predict(X_test),\n",
    "    display_labels=target_names,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3958eb",
   "metadata": {},
   "source": [
    "## Источники"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498840e9",
   "metadata": {},
   "source": [
    "[Simple audio recognition: Recognizing keywords](https://www.tensorflow.org/tutorials/audio/simple_audio?hl=en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce09154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
