{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "719e6a6c-65c6-4437-9b98-d3d0cd6679e6",
   "metadata": {},
   "source": [
    "# Semantic similarity and RAG\n",
    "\n",
    "---\n",
    "\n",
    "S.Yu. Papulin (papulin.study@yandex.ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d54a02c-b100-4b7b-b884-04a70b76a349",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "- [Semantic Similarity](#Semantic-Similarity)\n",
    "    - [Sentence Embedding with BERT](#Sentence-Embedding-with-BERT)\n",
    "    - [Pretrained for inference](#Pretrained-for-inference)\n",
    "    - [Sentence Transformer](#Sentence-Transformer)\n",
    "- [RAG using `llamaIndex`](#RAG-using-llamaIndex)\n",
    "    - [Basics](#Basics)\n",
    "    - [Hybrid Search](#Hybrid-Search)\n",
    "    - [Function Calling](#Function-Calling)\n",
    "- [Sources](#Sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d69ee7-433f-4240-926d-50652f70be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f80e170-7a47-4ab8-93fd-41a9ea2e7310",
   "metadata": {},
   "source": [
    "## Semantic Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275aaa53-41ff-4c5f-936f-27712482e9f3",
   "metadata": {},
   "source": [
    "### Sentence Embedding with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe72f4-d7f8-4ab9-8d65-bbfda11cc629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained model name\n",
    "CHECKPOINT = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cee13b-8c37-4624-bd99-ea7005c61a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokinezer associated with the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b8f3e-f42c-47ea-a7b5-a97361fb42d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~400MB\n",
    "model = TFAutoModel.from_pretrained(CHECKPOINT)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7127ab3b-0874-472f-ae2c-deefaad76bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ef33c2-e6b8-44ee-870b-8757e3f4e38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"Sport is your way to be stronger.\"\n",
    "\n",
    "SENTS = [\n",
    "    \"Technology drives our world to success.\",\n",
    "    \"Regular exercise strengthens the spirit.\",\n",
    "    \"Sport is the worst thing that was created.\",\n",
    "    \"Recent stock data shows that marker is on the down trend.\",\n",
    "    \"London is the capital of Great Britain.\",\n",
    "    \"Moscow is the capital of Russia.\",\n",
    "    \"Lyon is the capital of France.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca47a68b-c788-4818-a9ad-efaaaa1b19cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(input_text):\n",
    "    global tokenizer\n",
    "    return tokenizer(\n",
    "        input_text, \n",
    "        padding='max_length', \n",
    "        max_length=60, \n",
    "        truncation=True, \n",
    "        return_tensors='tf'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8035ff01-8bb1-495a-aebb-ee60b017a6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ids = tokenize_function(QUERY)\n",
    "q_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5133767-e2d0-49dc-8310-cf2010bda1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_ids = tokenize_function(SENTS)\n",
    "D_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14b8b6e-3cd1-47d4-a6f2-179ba6e12e69",
   "metadata": {},
   "source": [
    "**Pooler Ouput**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0398a1fe-c755-4e42-a838-43aabb6924fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(q_ids).pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e7d84-69dd-424f-8cc4-80a9a7a1dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bert(D_ids).pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e54ff8-e631-4d7a-9c7f-eec3050151fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_pooler(inputs):\n",
    "    global model\n",
    "    input_ids = tokenize_function(inputs)\n",
    "    return model.predict(input_ids).pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d150814-5909-45ed-a58f-8520c6ff969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_embed = get_embedding_pooler(QUERY)\n",
    "q_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b8a84c-7ec5-4700-b763-2ef97e8c7da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_embed = get_embedding_pooler(SENTS)\n",
    "D_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22ad41c-cf0e-4b93-a11f-d7513c4f7f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = cosine_similarity(q_embed, D_embed)\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9cfa7b-96e7-40cd-b6a5-1374838a5ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_by_similarity(query, docs, similatities):\n",
    "    index_sorted = (-similatities).argsort()\n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"Results:\")\n",
    "    for i, index in enumerate(index_sorted):\n",
    "        print(f\"{i+1}. {similatities[index]:.3f} -> {docs[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc1137f-95cc-4991-a93b-46405af5b628",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_by_similarity(QUERY, SENTS, sims[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feee7aec-9c09-40cb-941d-780a75fec80b",
   "metadata": {},
   "source": [
    "**Mean Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583ce473-c5a3-4969-b54c-24b8a3697889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_mean(inputs):\n",
    "    global model\n",
    "    input_ids = tokenize_function(inputs)\n",
    "    return tf.reduce_mean(model.predict(input_ids).last_hidden_state, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68695940-bcd4-4397-b8ca-3ef1f2e84b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_embed = get_embedding_mean(QUERY)\n",
    "D_embed = get_embedding_mean(SENTS)\n",
    "sims = cosine_similarity(q_embed, D_embed)\n",
    "print_by_similarity(QUERY, SENTS, sims[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c30af-da35-4249-8b14-53764fa984e4",
   "metadata": {},
   "source": [
    "**Masked Mean Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac1b70a-4037-4919-94b4-f00efe0803a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_masks(outputs, masks):\n",
    "    outputs_masks = tf.reshape(masks, [tf.shape(masks)[0], tf.shape(masks)[1], -1])\n",
    "    outputs_masks = tf.tile(outputs_masks, [1, 1, tf.shape(outputs)[2]])\n",
    "    return tf.where(\n",
    "        outputs_masks == 0,\n",
    "        tf.zeros_like(outputs),\n",
    "        outputs\n",
    "    )\n",
    "\n",
    "\n",
    "def get_embedding_mean_masked(inputs):\n",
    "    global model\n",
    "    input_ids = tokenize_function(inputs)\n",
    "    outputs = model.predict(input_ids).last_hidden_state\n",
    "    masks = input_ids['attention_mask']\n",
    "    outputs_masked = apply_masks(outputs, masks)\n",
    "    return tf.reduce_mean(outputs_masked, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4373ca2a-72ae-4b87-8a09-ec23f7f6f336",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_embed = get_embedding_mean_masked(QUERY)\n",
    "D_embed = get_embedding_mean_masked(SENTS)\n",
    "sims = cosine_similarity(q_embed, D_embed)\n",
    "print_by_similarity(QUERY, SENTS, sims[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576980f5-224c-4314-8b54-31456558c28e",
   "metadata": {},
   "source": [
    "### Pretrained for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c6e1fe-9b23-4c19-8e4d-597ada618822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: We need torch to use torch model with tensorflow\n",
    "# %pip install torch --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb29372-3e11-41c4-840c-5f962ead2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT = \"textattack/bert-base-uncased-snli\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a735ea-2708-4f11-aa15-8632b1747e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokinezer associated with the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7199fed6-50a4-4ada-a1e6-ef42739f22b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~1GB\n",
    "model = TFAutoModel.from_pretrained(CHECKPOINT, from_pt=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f311433c-5447-4d53-b169-ef6be9f1516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding with pooler\n",
    "q_embed = get_embedding_pooler(QUERY)\n",
    "D_embed = get_embedding_pooler(SENTS)\n",
    "sims = cosine_similarity(q_embed, D_embed)\n",
    "print_by_similarity(QUERY, SENTS, sims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5c36ca-6ff1-4301-a837-3534494b2db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding as mean of last hidden layer\n",
    "q_embed = get_embedding_mean(QUERY)\n",
    "D_embed = get_embedding_mean(SENTS)\n",
    "sims = cosine_similarity(q_embed, D_embed)\n",
    "print_by_similarity(QUERY, SENTS, sims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eff796-120f-4ac7-beeb-590104e997e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding as mean of last hidden layer with mask\n",
    "q_embed = get_embedding_mean_masked(QUERY)\n",
    "D_embed = get_embedding_mean_masked(SENTS)\n",
    "sims = cosine_similarity(q_embed, D_embed)\n",
    "print_by_similarity(QUERY, SENTS, sims[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a76dd58-a2ba-4b97-8728-5f218f2e995c",
   "metadata": {},
   "source": [
    "### Sentence Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c1f8c0-540a-4f18-85fb-89b561cb5c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ffe377-481c-482c-aeec-8551dba22d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72691513-b5a7-4b05-881e-53b46c08d8ff",
   "metadata": {},
   "source": [
    "#### Model `all-MiniLM-L6-v2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6440719e-90fc-4e5b-8964-1fe9f832ce24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e72ea38-8094-48f3-ac92-bbdb433b8b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_embed = model.encode(QUERY)\n",
    "D_embed = model.encode(SENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d88065-e585-4330-b2e5-b3a6a0c622e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = model.similarity(q_embed, D_embed)\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc3ea2c-08c6-4aa7-8529-b6b9df3e046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_by_similarity(QUERY, SENTS, sims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6844b69-1a15-4829-9649-174e02c48474",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f44e2ab-be37-485f-8772-3ac3908e81ac",
   "metadata": {},
   "source": [
    "#### Model `multilingual-e5-large-instruct`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d887e5d-2cd7-40ed-b25c-92aca5726b87",
   "metadata": {},
   "source": [
    "**Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb85d5a0-6eef-4490-9ba6-ba15e28c3c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"intfloat/multilingual-e5-large-instruct\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fda3ef-39d8-4f74-be76-459d9a62910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_embed = model.encode(QUERY)\n",
    "D_embed = model.encode(SENTS)\n",
    "sims = model.similarity(q_embed, D_embed)\n",
    "print_by_similarity(QUERY, SENTS, sims[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d92b76-7d9a-4db1-9ec8-a895ad264345",
   "metadata": {},
   "source": [
    "**Instruction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea51b16-6cd4-40de-996a-74e53b5141a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detailed_instruct(task_description, query):\n",
    "    return f'Instruct: {task_description}\\nQuery: {query}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebceceb-2d93-46ab-bef3-e3883edf66d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'Given a web search query, retrieve relevant passages that answer the query'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd2d79b-c935-4a8d-83de-883dd0886406",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"What makes you stronger?\",\n",
    "    \"What is tha capital of Great Britain?\",\n",
    "    \"What is tha capital of France?\",\n",
    "    \"What is tha capital of Germany?\"\n",
    "]\n",
    "\n",
    "prompts = [get_detailed_instruct(task, query) for query in queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a446fd06-624a-48f3-bd66-efd873843313",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_embed = model.encode(prompts)\n",
    "D_embed = model.encode(SENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c2a62d-e382-4e3e-b3b0-72d11e85ca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = model.similarity(Q_embed, D_embed)\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1817c6-0451-4864-bb7d-1968d752f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_by_similarity(queries[0], SENTS, sims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8af173-72a8-408e-9898-9f0133e5d6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_by_similarity(queries[1], SENTS, sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9fe7d4-19b4-456e-aa73-dad5b06ce1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_by_similarity(queries[2], SENTS, sims[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a52e7d7-c259-4ef3-8a80-48ac7d1045b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_by_similarity(queries[3], SENTS, sims[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37245c5b-ec6b-4efb-a850-45a14105a236",
   "metadata": {},
   "source": [
    "## RAG using `llamaIndex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692c832a-1984-4d2e-ae76-3295dcbddfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install \\\n",
    "# llama-index-core \\\n",
    "# llama-index-readers-file \\\n",
    "# llama-index-readers-string-iterable \\\n",
    "# llama-index-llms-ollama \\\n",
    "# llama-index-embeddings-huggingface \\\n",
    "# llama-index-llms-huggingface \\\n",
    "# llama-index-llms-deepseek \\\n",
    "# llama-index-retrievers-bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c37c8af-2008-4761-8a27-5a17ca194de3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Readers\n",
    "from llama_index.readers.string_iterable import StringIterableReader\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# Model\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "# Index\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.vector_stores import VectorStoreQuery\n",
    "\n",
    "# Retriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from llama_index.core.retrievers import QueryFusionRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f91c4e-9c9c-467b-8d39-4eb13b156f6d",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://docs.llamaindex.ai/en/stable/_static/getting_started/basic_rag.png\" width=\"70%\"/>\n",
    "</center>\n",
    "\n",
    "#### Retrieval-Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffee7335-79ef-4d12-a785-74ae0cc741fd",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://docs.llamaindex.ai/en/stable/_static/getting_started/stages.png\" width=\"70%\"/>\n",
    "</center>\n",
    "\n",
    "#### Stages within RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d59519-a691-4fc6-9b4b-1561b0c49c73",
   "metadata": {},
   "source": [
    "### Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cf8e5d-a949-45fe-a3bb-ab273c28224f",
   "metadata": {},
   "source": [
    "**Documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7040557-1191-4975-b462-43ddb7ac65ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "documents = StringIterableReader().load_data(\n",
    "    texts=SENTS\n",
    ")\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e08355a-5218-4975-9d33-d28125342224",
   "metadata": {},
   "source": [
    "**Embedding and vector storage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cebd87-074e-463e-b2d7-aff967d6aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model (~133M)\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d30a35d-76f1-4043-911b-3ad195d39533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    embed_model=embed_model,\n",
    "    show_progress=True\n",
    ")\n",
    "type(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65e0d3d-dc0b-4fe2-b810-d2b37c268ece",
   "metadata": {},
   "source": [
    "⚠️ **Warning.** We use in-memory storage. For more complex tasks, use a vector storage such as `Qdrant`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17c68fd-cf7d-4853-be4d-f096881fdef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(index.docstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0613286d-b335-4714-b5d2-0736cc1f1920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match document id and node id (chunks of document)\n",
    "index.docstore.get_all_ref_doc_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3e9afb-3949-4d6f-8714-342889c44a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some node id\n",
    "node_id = list(index.docstore.docs.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317452b5-0f97-439e-a56b-5633b48446b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node detail\n",
    "index.docstore.get_node(node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe7ae11-2f39-47b9-8c9d-d179d7f023db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match nodes and documents\n",
    "index.vector_store.data.text_id_to_ref_doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492fd7c9-41e4-4d60-b876-aa2b64afc74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings (384) of document chunk\n",
    "index.vector_store.data.embedding_dict[node_id][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd18b2d4-d35a-4244-94f3-b882c1f0e81e",
   "metadata": {},
   "source": [
    "**Retrieval. Semantic similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b41b59-94df-47ec-b1e7-20191f675f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUERY = \"What is tha capital of Great Britain?\"\n",
    "QUERY = \"Sport is your way to be stronger.\"\n",
    "\n",
    "q_embed = embed_model.get_query_embedding(QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5937c493-9b67-4626-bff1-7109c926e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_query = VectorStoreQuery(\n",
    "    query_embedding=q_embed, \n",
    "    similarity_top_k=7, \n",
    "    mode=\"default\"\n",
    ")\n",
    "result = index.vector_store.query(query=vector_store_query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1773506b-6ea5-49c3-bb6e-892b148789ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_texts = [index.docstore.get_node(node_id).text for node_id in result.ids]\n",
    "\n",
    "print_by_similarity(QUERY, node_texts, np.array(result.similarities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0402ef4-1ba2-46a9-8430-277ab020a78b",
   "metadata": {},
   "source": [
    "**Generator with LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f255ae5c-7d0f-442d-8bc6-0007510ff833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tiny_llama_llm(checkpoint=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"):\n",
    "    \"\"\"~2.24G\"\"\"\n",
    "    return HuggingFaceLLM(\n",
    "        model_name=checkpoint, \n",
    "        tokenizer_name=checkpoint,\n",
    "        system_prompt=\"You are a helpful assistant\",\n",
    "        context_window=2048,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_phi_llm(checkpoint=\"microsoft/phi-3-mini-4k-instruct\"):\n",
    "    \"\"\"~8G\"\"\"\n",
    "    from transformers import AutoTokenizer\n",
    "\n",
    "    # def message_to_prompt(messages):\n",
    "    #     return f\"<|user|>\\n{messages[-1].content}<|end|>\\n<|assistant|>\"\n",
    "\n",
    "    def completion_to_prompt(completion):\n",
    "        return f\"<|user|>\\n{completion}<|end|>\\n<|assistant|>\"\n",
    "    \n",
    "    # Note: We load tokenizer to get eos_token_id\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        checkpoint,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    return HuggingFaceLLM(\n",
    "        model_name=checkpoint, \n",
    "        tokenizer_name=checkpoint,\n",
    "        # messages_to_prompt=message_to_prompt,\n",
    "        completion_to_prompt=completion_to_prompt,\n",
    "        context_window=2048,\n",
    "        device_map=\"auto\",\n",
    "        stopping_ids=[tokenizer.eos_token_id,],\n",
    "        generate_kwargs={\n",
    "            \"temperature\": 0.3, \n",
    "            \"do_sample\": True, \n",
    "            \"top_p\": 0.95,\n",
    "            \"early_stopping\": True\n",
    "            # \"use_cache\": False,\n",
    "        },\n",
    "        model_kwargs={\n",
    "            \"torch_dtype\": \"auto\", \n",
    "            # \"trust_remote_code\": True,\n",
    "            # \"low_cpu_mem_usage\": True,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_as_stream(llm, prompt):\n",
    "    for chunk in llm.stream_complete(prompt):\n",
    "        print(chunk.delta, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f809505-0540-4e2d-8597-437b6ee087c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = load_phi_llm()\n",
    "llm = load_tiny_llama_llm()\n",
    "llm.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ad847f-e27f-4fc1-9423-801c6d558761",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"What is the capital of France?\"\n",
    "\n",
    "# stream output of complete\n",
    "generate_as_stream(llm, QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f4cd9a-e5b1-48c9-95b1-881e354885ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entire output of complete\n",
    "response = llm.complete(QUERY)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de543a8-1bee-4144-ae55-0d041c03f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "response = llm.chat([ChatMessage(role=\"user\", content=QUERY)])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a05f63-2637-40eb-bd6f-ee0436727d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1\n",
    "vector_retriever = index.as_retriever()\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever=vector_retriever, \n",
    "    llm=llm,\n",
    "    similarity_top_k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09931b64-14c3-41e9-81d3-be88f97c7b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2 (recommended)\n",
    "query_engine = index.as_query_engine(\n",
    "    llm=llm,\n",
    "    similarity_top_k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbb6301-2f14-4f8c-bd93-a8076a74a6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"What is a way to be stronger?\"\n",
    "# QUERY = \"What is tha capital of Great Britain?\"\n",
    "# QUERY = \"What is tha capital of Germany?\"\n",
    "# QUERY = \"What is tha capital of France?\"\n",
    "# QUERY = \"Do you think the capital of France is Lyon or Paris?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcb562a-d8f5-4cc2-824e-08662c7398ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(QUERY)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba83fdd-813c-4651-8cc3-9a91ff47eb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebab33d-e665-464a-97cb-da241f9951bd",
   "metadata": {},
   "source": [
    "### Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35552899-18f9-45e1-94d8-e79a4c6f9ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cfed2c-e902-4e4e-a1c8-34e744356fa9",
   "metadata": {},
   "source": [
    "**Keywords Search using BM25 Retriever**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79af297-20bb-4fd8-a956-0b97860759ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"Do you think the capital of France is Lyon or Paris?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75e609c-8f93-4fda-84e2-55b874b51832",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_defaults(\n",
    "    # index=index, \n",
    "    docstore=index.docstore,\n",
    "    similarity_top_k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b925a6-92ac-4c82-9e96-e1225a7e484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = bm25_retriever.retrieve(QUERY)\n",
    "nodes[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2abee2-face-4b21-91ff-dec7b10b7d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in nodes:\n",
    "    display_source_node(node, source_length=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab85b1-1d14-4f27-b337-fa69d5aa9f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine with LLM\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    llm=llm,\n",
    "    retriever=bm25_retriever, \n",
    "    similarity_top_k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62ff8ec-d7df-417c-aa65-06cf7375ed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query_engine.query(QUERY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b0d9c9-9fee-4070-8d72-aa28ef7e5518",
   "metadata": {},
   "source": [
    "**Hybrid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316e69c3-a259-47e2-9fad-5cf5c627853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_retriever = QueryFusionRetriever(\n",
    "    llm=llm,\n",
    "    retrievers=[vector_retriever, bm25_retriever],\n",
    "    similarity_top_k=3,\n",
    "    num_queries=1,\n",
    "    retriever_weights=[0.7, 0.3],\n",
    "    # mode=\"reciprocal_rerank\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2200faa-180c-40bd-8dbe-ea37e0c8982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = hybrid_retriever.retrieve(QUERY)\n",
    "for node in nodes:\n",
    "    display_source_node(node, source_length=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb8da99-d90f-4e21-800a-cad2efbc8295",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    llm=llm,\n",
    "    retriever=hybrid_retriever, \n",
    "    similarity_top_k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf4349f-c5ae-48b4-ab85-a955ff041cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query_engine.query(QUERY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2b921a-bc2d-4aef-b7cc-62ea02d7a70b",
   "metadata": {},
   "source": [
    "### Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba164958-c20b-4f76-b9cd-73e149828dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.agent.workflow import ReActAgent, FunctionAgent, ToolCallResult\n",
    "from llama_index.core.workflow import Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafe4f3a-e08e-424b-b453-f759beb0f417",
   "metadata": {},
   "source": [
    "⚠️ **Warning.** Small LLMs are not a good option for this task. So, below code doesn't call tools. Use more advanced models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d215f35-3f66-4f2c-bbbe-ca7cd92601f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_deepseek_llm():\n",
    "    from llama_index.llms.deepseek import DeepSeek\n",
    "    import os\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    return DeepSeek(\n",
    "        model=\"deepseek-chat\", \n",
    "        api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n",
    "        system_prompt=\"You are a helpful assistant.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d24ab01-e507-418c-9a87-91927cb04967",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = load_deepseek_llm()\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b38bfd8-afd2-400a-9404-2f4ff838d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e4d709-ed69-4d27-b70c-2ac7cc2aa08a",
   "metadata": {},
   "source": [
    "**Basics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f700e9b-d73e-436d-84a0-897e3e76e11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(region: str) -> int:\n",
    "    \"\"\"Weather of region provided\"\"\"\n",
    "    return 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e55e8e1-7f29-4470-bf5f-9b07fce1e958",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tool = FunctionTool.from_defaults(\n",
    "    fn=get_weather,\n",
    "    name=\"get_weather\",\n",
    "    description=\"Get weather condition in specified region\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141debc0-aebc-4466-b5dd-59e224e45cbd",
   "metadata": {},
   "source": [
    "`ReActAgent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63398ff-fefb-458d-a681-c3ce0ddbce79",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent(\n",
    "    tools=[weather_tool], \n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "# Create a context to store the conversation history/session state\n",
    "# ctx = Context(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64b5afd-7c3a-4511-a8a2-898ce2df1098",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await agent.run(\"What is the weather in Paris?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eef8d67-951d-4f66-aea1-a5abf6c7f44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8624e278-c557-48e9-8915-100c204605e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4654f54c-1c11-4159-abd4-4cb79017075d",
   "metadata": {},
   "source": [
    "`FunctionAgent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbc8223-745b-4ef9-8c1b-3ff2a9d48c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.is_function_calling_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ff55d-03fc-432d-a451-c87873dea979",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = FunctionAgent(\n",
    "    tools=[weather_tool],\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42abe987-4887-4d74-b0c4-c074905819a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await agent.run(\"What is the weather in Paris?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f11c75-d7f5-4782-a8a3-a87db0d9d1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1fb0f8-5f46-4843-aac1-1c8392c95f66",
   "metadata": {},
   "source": [
    "**Combining with search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897b4c3d-ebca-4bd1-be13-95dd304d8e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query: str) -> str:\n",
    "    return str(query_engine.query(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ef783d-c673-4ed4-b17d-24de30126026",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = FunctionTool.from_defaults(\n",
    "    fn=search,\n",
    "    name=\"search\",\n",
    "    description=\"Search for information based on user predefined context. Represent the query as a question.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ce6cfc-89b0-4e3f-927c-4e65c0cd69c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent(tools=[weather_tool, search_tool], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7242a26b-436c-4267-8c6e-943ce608cd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"What is the weather in Lyon, and what is the capital of France?\"\n",
    "# QUERY = \"Do you think the capital of France is Lyon or Paris?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b71b54-954d-4f73-bfc5-2b3f697a15ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await agent.run(QUERY)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b21561b-bb2f-4987-892d-741a4e3af2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36380db-7f7f-4e60-b126-e381e7c52acd",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bdc8b0-8222-4741-81fc-72d7eeddfff6",
   "metadata": {},
   "source": [
    "- [Building an LLM application](https://docs.llamaindex.ai/en/stable/understanding/)\n",
    "- [Local Embeddings with HuggingFace](https://docs.llamaindex.ai/en/stable/examples/embeddings/huggingface/)\n",
    "- [Hugging Face LLMs](https://docs.llamaindex.ai/en/stable/examples/llm/huggingface/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
