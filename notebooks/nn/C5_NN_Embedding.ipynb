{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01e9972a",
   "metadata": {},
   "source": [
    "# Векторное представление слов\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "С.Ю. Папулин (papulin.study@yandex.ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dafdf7b",
   "metadata": {},
   "source": [
    "### Содержание\n",
    "\n",
    "- [Векторное представление GloVe](#Векторное-представление-GloVe)\n",
    "- [Классификация текстовых документов](#Классификация-текстовых-документов)\n",
    "- [Слой векторного представления слов в Keras/TensorFlow](#Слой-векторного-представления-слов-в-Keras/TensorFlow)\n",
    "- [Источники](#Источники)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c674f43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a15cff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e106ad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82dc489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba7679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94b63d6",
   "metadata": {},
   "source": [
    "## Векторное представление `GloVe`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3f5bc5",
   "metadata": {},
   "source": [
    "Предобученная модель `GloVe` [[ссылка](https://github.com/stanfordnlp/GloVe)]. Далее используется модель, обученная на Wikipedia 2014 + Gigaword 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06acb20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8df478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(path_to_file):\n",
    "    \"\"\"Загрузка словаря и весов.\"\"\"\n",
    "    embeddings_index = {}\n",
    "    with open(path_to_file) as f:\n",
    "        for line in f:\n",
    "            word, coefs = line.split(maxsplit=1)\n",
    "            coefs = np.fromstring(coefs, 'f', sep=' ')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017c074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Размерность вектора слов\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "# Загрузка модели\n",
    "FILEPATH = f'/YOUR_PATH/glove.6B/glove.6B.{EMBEDDING_DIM}d.txt'\n",
    "embeddings_index = load_vectors(FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c22dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Массив слова\n",
    "words = np.array(list(embeddings_index.keys()))\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db51d70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Массив весов слов\n",
    "E = np.zeros((len(embeddings_index), EMBEDDING_DIM))\n",
    "for indx, (word, vector) in enumerate(embeddings_index.items()):\n",
    "    E[indx] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31ca9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список запросов\n",
    "q1 = embeddings_index['king']\n",
    "q2 = embeddings_index['king'] - embeddings_index['man'] + embeddings_index['woman']\n",
    "q3 = embeddings_index['soldier'] - embeddings_index['braveness']\n",
    "q4 = embeddings_index['unemployment'] + embeddings_index['work']\n",
    "q5 = embeddings_index['democracy'] - embeddings_index['law'] + embeddings_index['corruption']\n",
    "q6 = embeddings_index['pilot'] - embeddings_index['plane'] +  embeddings_index['car']\n",
    "\n",
    "Q = np.vstack([q1, q2, q3, q4, q5, q6])\n",
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e2a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисление косинусного сходства (дистанция от 0 до 1)\n",
    "S = 1 - cosine_similarity(E, Q)\n",
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c94ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список слова запросов\n",
    "query_words = [\n",
    "    ['king'], \n",
    "    ['king', 'man', 'woman'],\n",
    "    ['soldier', 'braveness'],\n",
    "    ['unemployment', 'work'],\n",
    "    ['democracy', 'law', 'corruption'],\n",
    "    ['pilot', 'plane', 'car']\n",
    "]\n",
    "\n",
    "n_top = 10  # топ-10 слов релевантных запросу\n",
    "\n",
    "W_top = np.empty((S.shape[1], n_top), dtype='object')\n",
    "\n",
    "for i in range(S.shape[1]):\n",
    "    \"\"\"\n",
    "    Удаляем из результата слова запроса и\n",
    "    сохраняем топ-n слов для каждого запроса\n",
    "    \"\"\"\n",
    "    # Фильтруем слова i-го запроса\n",
    "    mask = np.isin(words, query_words[i])\n",
    "    # Применяем фильтр, сортируем по близости и \n",
    "    # оставляем топ 10\n",
    "    W_top[i] = words[~mask][S[~mask, i].argsort()][:n_top]\n",
    "\n",
    "# Вывод в виде датафрейма\n",
    "pd.DataFrame(data=W_top.T, columns=[f\"q{i+1}\" for i in range(W_top.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2425c60",
   "metadata": {},
   "source": [
    "## Классификация текстовых документов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612b3f58",
   "metadata": {},
   "source": [
    "### Загрузка набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12dc35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b9d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_20newsgroups(\n",
    "    subset=\"all\", \n",
    "    shuffle=True, \n",
    "    remove=(\"headers\", \"footers\", \"quotes\"), \n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953565b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array(data.target_names)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b35903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data):\n",
    "    X = np.array(data.data, dtype='object')\n",
    "    y = data.target\n",
    "    X, y = shuffle(X, y, random_state=RANDOM_STATE)\n",
    "    topics = (names=='comp.graphics')\\\n",
    "        | (names=='comp.os.ms-windows.misc')\\\n",
    "        | (names=='comp.sys.ibm.pc.hardware')\\\n",
    "        | (names=='comp.sys.mac.hardware')\\\n",
    "        | (names=='comp.windows.x')\\\n",
    "        | (names=='sci.electronics')\n",
    "    topic_labels = np.where(topics)[0]\n",
    "    topics_mask = np.isin(y, topic_labels)\n",
    "    X_pos = X[topics_mask]\n",
    "    n_pos = X_pos.shape[0]\n",
    "    X_neg = X[~topics_mask][:n_pos]\n",
    "    y_pos, y_neg = np.ones(n_pos), np.zeros(n_pos)\n",
    "    return shuffle(np.r_[X_pos, X_neg], np.r_[y_pos, y_neg], random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d551a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_dataset(data)\n",
    "X[:2], y[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027962d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b7edbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя длина текста в символах\n",
    "np.mean(list(map(lambda x: len(x), X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6966491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формирование тестового множества\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "# Формирование проверочного множества\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, \n",
    "    test_size=0.3, \n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13c7eef",
   "metadata": {},
   "source": [
    "### Преобразование документов в вектор"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9a3b0e",
   "metadata": {},
   "source": [
    "#### Наивный Байес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5956b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a4324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a7b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=True, stop_words=\"english\",\n",
    "                             use_idf=False, ngram_range=(1,1),\n",
    "                             max_features=NUM_FEATURES,\n",
    "                             smooth_idf=True)\n",
    "clr = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dcbba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('clr', clr)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23811866",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_trainval, y_trainval)\n",
    "# Доля правильных классификаций на тестовом подмножестве\n",
    "print(\"Accuracy =\", pipeline.score(X_test, y_test))\n",
    "print(\"Precision =\", precision_score(pipeline.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8850d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = \"\"\"\n",
    "OpenAI Chief Technology Officer Mira Murati said the updated version of ChatGPT will \n",
    "now also have memory capabilities, meaning it can learn from previous conversations \n",
    "with users, and can do real-time translation.\n",
    "\n",
    "“This is the first time that we are really making a huge step forward when it comes to \n",
    "the ease of use,” Murati said during the live demo from the company’s San Francisco \n",
    "headquarters. “This interaction becomes much more natural and far, far easier.”\n",
    "\n",
    "The new release comes as OpenAI seeks to stay ahead of the growing competition in the \n",
    "AI arms race. Rivals including Google and Meta have been working to build increasingly \n",
    "powerful large language models that power chatbots and can be used to bring AI technology \n",
    "to various other products.\n",
    "\n",
    "The OpenAI event came one day ahead of Google’s annual I/O developer conference, at which \n",
    "it’s expected to announce updates to its Gemini AI model. Like the new GPT-4o, Google’s \n",
    "Gemini is also multimodal, meaning it can interpret and generate text, images and audio. \n",
    "OpenAI’s update also comes ahead of expected AI announcements from Apple at its Worldwide \n",
    "Developers Conference next month, which could include new ways of incorporating AI into \n",
    "the next iPhone or iOS releases.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e710bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.predict([new_text, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6396b737",
   "metadata": {},
   "source": [
    "#### Метод опорных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c935ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb558080",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('clr', LinearSVC())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_trainval, y_trainval)\n",
    "# Доля правильных классификаций на тестовом подмножестве\n",
    "print(\"Accuracy =\", pipeline.score(X_test, y_test))\n",
    "print(\"Precision =\", precision_score(pipeline.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec94248",
   "metadata": {},
   "source": [
    "### Преобразование слов в вектор с использованием предобученной матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dbebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_mean_text(X, E_dict, analyzer):\n",
    "    X_ = np.zeros((len(X), EMBEDDING_DIM))\n",
    "    for i, post in enumerate(X):\n",
    "        words = analyzer(post)\n",
    "        words_vectors = [E_dict.get(word) for word in words if word in E_dict]\n",
    "        if words_vectors:\n",
    "            X_[i] = np.vstack(words_vectors).mean(axis=0)\n",
    "    return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3c01d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = vectorizer.build_tokenizer()  # разбивает текст на слова\n",
    "analyzer = vectorizer.build_analyzer()    # tokenizer + применяет преобразования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee4da7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = analyzer(X[0])\n",
    "words, len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94385f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval__mean_emb = convert_to_mean_text(\n",
    "    X=X_trainval, \n",
    "    E_dict=embeddings_index, \n",
    "    analyzer=analyzer\n",
    ")\n",
    "X_test__mean_emb = convert_to_mean_text(\n",
    "    X=X_test, \n",
    "    E_dict=embeddings_index, \n",
    "    analyzer=analyzer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0753e8",
   "metadata": {},
   "source": [
    "#### Метод опорных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b9f041",
   "metadata": {},
   "outputs": [],
   "source": [
    "clr = SVC(kernel='rbf', gamma='scale')\n",
    "clr.fit(X_trainval__mean_emb, y_trainval)\n",
    "# Доля правильных классификаций на тестовом подмножестве\n",
    "print(\"Accuracy =\", clr.score(X_test__mean_emb, y_test))\n",
    "print(\"Precision =\", precision_score(clr.predict(X_test__mean_emb), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d772ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clr.predict(\n",
    "    convert_to_mean_text(\n",
    "        X=[new_text, ], \n",
    "        E_dict=embeddings_index, \n",
    "        analyzer=analyzer\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbd92e7",
   "metadata": {},
   "source": [
    "#### Многослойная нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d214bc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val_scores(train_history):\n",
    "    \n",
    "    INDX = 0\n",
    "\n",
    "    # Построение графиков ошибок обучения\n",
    "    plt.figure(figsize=[14, 4])\n",
    "\n",
    "    epochs = np.arange(1, len(train_history.history[\"loss\"])+1)\n",
    "\n",
    "    plt.subplot(1,2,1)  # кросс-энтропия\n",
    "    plt.plot(epochs[INDX:], train_history.history[\"loss\"][INDX:], \"-og\", label=\"train\")\n",
    "    plt.plot(epochs[INDX:], train_history.history[\"val_loss\"][INDX:], \"-o\", color=\"orange\", label=\"val\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)  # доля правильных классификаций\n",
    "    plt.plot(epochs[INDX:], train_history.history[\"binary_accuracy\"][INDX:], \"-og\", label=\"train\")\n",
    "    plt.plot(epochs[INDX:], train_history.history[\"val_binary_accuracy\"][INDX:], \"-o\", color=\"orange\", label=\"val\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc3a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train__mean_emb = convert_to_mean_text(\n",
    "    X=X_train, \n",
    "    E_dict=embeddings_index, \n",
    "    analyzer=analyzer\n",
    ")\n",
    "X_val__mean_emb = convert_to_mean_text(\n",
    "    X=X_val, \n",
    "    E_dict=embeddings_index, \n",
    "    analyzer=analyzer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4422c9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128, activation=\"relu\", input_shape=(EMBEDDING_DIM,)))\n",
    "    model.add(layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.Precision()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d2a11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение модели\n",
    "model = build_model()\n",
    "\n",
    "# Описание модели\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a8601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение\n",
    "train_history = model.fit(\n",
    "    X_train__mean_emb, y_train, \n",
    "    epochs=30, \n",
    "    validation_data=(X_val__mean_emb, y_val),\n",
    "    batch_size=50,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ddb67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_val_scores(train_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0534bc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем количество эпох и заново обучаем сеть на всём обучающем множестве\n",
    "best_num_epochs = 10\n",
    "\n",
    "# Построение модели\n",
    "model = build_model()\n",
    "\n",
    "# Обучение\n",
    "train_history = model.fit(X_trainval__mean_emb, y_trainval,\n",
    "                          epochs=best_num_epochs, \n",
    "                          batch_size=50,\n",
    "                          verbose=1)\n",
    "\n",
    "# Оценка качества модели\n",
    "_, train_error__acc, train_error__prec = model.evaluate(X_trainval__mean_emb, y_trainval)\n",
    "_, test_error__acc, test_error__prec = model.evaluate(X_test__mean_emb, y_test)\n",
    "\n",
    "print(\"Train:\\n\")\n",
    "print(\"\\tAccuracy = \\t\", train_error__acc)\n",
    "print(\"\\tPrecision = \\t\", train_error__prec)\n",
    "print(\"Test:\\n\")\n",
    "print(\"\\tAccuracy = \\t\", test_error__acc)\n",
    "print(\"\\tPrecision = \\t\", test_error__prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac7c2eb",
   "metadata": {},
   "source": [
    "## Слой векторного представления слов в Keras/TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e661db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76416cf8",
   "metadata": {},
   "source": [
    "### Подготовка набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28892674",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f80eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Набор данных для выбора эпохи\n",
    "\"\"\"\n",
    "\n",
    "# Обучение\n",
    "X_train__batches = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "y_train__batches = tf.data.Dataset.from_tensor_slices(y_train)\n",
    "\n",
    "train__batches = (\n",
    "    tf.data.Dataset.zip((X_train__batches, y_train__batches))\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# Проверка\n",
    "X_val__batches = tf.data.Dataset.from_tensor_slices(X_val)\n",
    "y_val__batches = tf.data.Dataset.from_tensor_slices(y_val)\n",
    "\n",
    "val__batches = (\n",
    "    tf.data.Dataset.zip((X_val__batches, y_val__batches))\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "\n",
    "for batch in train__batches.take(1):\n",
    "    print(batch[0].shape, batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7322a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Набор данных для повторного обучения и тестирования\n",
    "\"\"\"\n",
    "\n",
    "# Обучение\n",
    "X_trainval__batches = tf.data.Dataset.from_tensor_slices(X_trainval)\n",
    "y_trainval__batches = tf.data.Dataset.from_tensor_slices(y_trainval)\n",
    "\n",
    "trainval__batches = (\n",
    "    tf.data.Dataset.zip((X_trainval__batches, y_trainval__batches))\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# Тестирование\n",
    "X_test__batches = tf.data.Dataset.from_tensor_slices(X_test)\n",
    "y_test__batches = tf.data.Dataset.from_tensor_slices(y_test)\n",
    "\n",
    "test__batches = (\n",
    "    tf.data.Dataset.zip((X_test__batches, y_test__batches))\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fece151d",
   "metadata": {},
   "source": [
    "### Слой преобразования слов в индексы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3bf4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TEXT_LENGTH = 200\n",
    "NUM_FEATURES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654d327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование текста в набор индексов словаря\n",
    "vectorizer_layer = layers.TextVectorization(\n",
    "    max_tokens=NUM_FEATURES, \n",
    "    output_sequence_length=MAX_TEXT_LENGTH\n",
    ")\n",
    "\n",
    "# Формирование словаря\n",
    "vectorizer_layer.adapt(X_train__batches)\n",
    "\n",
    "print(f'Количество элементов словаря:\\t{len(vectorizer_layer.get_vocabulary())}')\n",
    "print(f'Первые элементы словаря:\\t{vectorizer_layer.get_vocabulary()[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f027e9d",
   "metadata": {},
   "source": [
    "### Инициализация слоя векторизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ac9eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формирование матрицы весов для embedding слоя\n",
    "E = np.zeros((NUM_FEATURES, EMBEDDING_DIM))\n",
    "for i, word in enumerate(vectorizer_layer.get_vocabulary()):\n",
    "    if word in embeddings_index:\n",
    "        E[i] = embeddings_index.get(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b102acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация embedding слоя\n",
    "embedding_layer = Embedding(\n",
    "    input_dim=NUM_FEATURES,\n",
    "    output_dim=EMBEDDING_DIM,\n",
    "    input_length=MAX_TEXT_LENGTH,\n",
    "    trainable=False  # отключаем обучение слоя\n",
    ")\n",
    "\n",
    "# Инициализация весов\n",
    "embedding_layer.build((1,))\n",
    "\n",
    "# Установка весов\n",
    "embedding_layer.set_weights([E])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662eb1f0",
   "metadata": {},
   "source": [
    "### Построение и обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc482684",
   "metadata": {},
   "source": [
    "#### Модель 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619084c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(vectorizer_layer)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.Precision()]\n",
    "    )\n",
    "    model.build(input_shape=(1, ))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa790f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение модели\n",
    "model = build_model()\n",
    "\n",
    "# Описание модели\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c9369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение\n",
    "train_history = model.fit(\n",
    "    train__batches, \n",
    "    epochs=20, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=val__batches,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a474046",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_val_scores(train_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1826bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем количество эпох и заново обучаем сеть на всём обучающем множестве\n",
    "best_num_epochs = 5\n",
    "\n",
    "# Построение модели\n",
    "model = build_model()\n",
    "\n",
    "# Обучение\n",
    "train_history = model.fit(trainval__batches,\n",
    "                          epochs=best_num_epochs, \n",
    "                          batch_size=50,\n",
    "                          verbose=1)\n",
    "\n",
    "# Оценка качества модели\n",
    "_, train_error__acc, train_error__prec = model.evaluate(trainval__batches)\n",
    "_, test_error__acc, test_error__prec = model.evaluate(test__batches)\n",
    "\n",
    "print(\"Train:\\n\")\n",
    "print(\"\\tAccuracy = \\t\", train_error__acc)\n",
    "print(\"\\tPrecision = \\t\", train_error__prec)\n",
    "print(\"Test:\\n\")\n",
    "print(\"\\tAccuracy = \\t\", test_error__acc)\n",
    "print(\"\\tPrecision = \\t\", test_error__prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e00349b",
   "metadata": {},
   "source": [
    "#### Модель 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792b5de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(vectorizer_layer)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(layers.Bidirectional(layers.LSTM(32)))\n",
    "    model.add(layers.Dense(32, activation=\"relu\"))\n",
    "    model.add(layers.Dense(1,  activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.Precision()])\n",
    "    model.build(input_shape=(1, ))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca8333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение модели\n",
    "model = build_model()\n",
    "\n",
    "# Вывод описания модели\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22888397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запуск обучения\n",
    "train_history = model.fit(\n",
    "    train__batches, \n",
    "    epochs=10, \n",
    "    batch_size=128,\n",
    "    validation_data=val__batches,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ad89ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_val_scores(train_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def45f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем количество эпох и заново обучаем сеть на всём обучающем множестве\n",
    "best_num_epochs = 10\n",
    "\n",
    "# Построение модели\n",
    "model = build_model()\n",
    "\n",
    "# Обучение\n",
    "train_history = model.fit(trainval__batches,\n",
    "                          epochs=best_num_epochs, \n",
    "                          batch_size=128,\n",
    "                          verbose=1)\n",
    "\n",
    "# Оценка качества модели\n",
    "_, train_error__acc, train_error__prec = model.evaluate(trainval__batches)\n",
    "_, test_error__acc, test_error__prec = model.evaluate(test__batches)\n",
    "\n",
    "print(\"Train:\\n\")\n",
    "print(\"\\tAccuracy = \\t\", train_error__acc)\n",
    "print(\"\\tPrecision = \\t\", train_error__prec)\n",
    "print(\"Test:\\n\")\n",
    "print(\"\\tAccuracy = \\t\", test_error__acc)\n",
    "print(\"\\tPrecision = \\t\", test_error__prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d76a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказание для новых данных\n",
    "model.predict([new_text,])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31e5309",
   "metadata": {},
   "source": [
    "### Слои модели нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7264c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список слоев\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb76e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Имена слоев\n",
    "[layer.name for layer in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08090f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Доступ к слою по имени\n",
    "layer = model.get_layer('embedding')\n",
    "print(f'Trainable weights: {layer.trainable_variables}')\n",
    "print(f'Non-trainable weights: {layer.non_trainable_variables}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f096511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выходные данные 1го слоя\n",
    "output_l1 = model.layers[0](np.array(new_text))\n",
    "output_l1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fa4445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выходные данные 2го слоя\n",
    "output_l2 = model.layers[1](output_l1)\n",
    "output_l2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6fa041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выходные данные 3го слоя\n",
    "output_l3 = model.layers[2](np.array([output_l2]))\n",
    "output_l3.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a1fcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выходные данные 4го слоя\n",
    "output_l4 = model.layers[3](output_l3)\n",
    "output_l4.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac02c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выходные данные 5го слоя\n",
    "output_l5 = model.layers[4](output_l4)\n",
    "output_l5.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a13e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказание\n",
    "model.predict([new_text,])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc609fb9",
   "metadata": {},
   "source": [
    "### Обучение слоя векторного представления слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3555ae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(vectorizer_layer)\n",
    "    model.add(layers.Embedding(\n",
    "        input_length=MAX_TEXT_LENGTH,\n",
    "        input_dim=NUM_FEATURES,\n",
    "        output_dim=128,\n",
    "        mask_zero=True))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.Precision()])\n",
    "    model.build(input_shape=(1,))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b53ab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение модели\n",
    "model = build_model()\n",
    "\n",
    "# Вывод описания модели\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0aa078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запуск обучения\n",
    "train_history = model.fit(\n",
    "    train__batches, \n",
    "    epochs=30, \n",
    "    batch_size=128,\n",
    "    validation_data=val__batches,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f12f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Извлечение весов словаря\n",
    "E_new = model.layers[1].get_weights()[0]\n",
    "E_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb174b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Массив слова словаря\n",
    "words_new = np.array(vectorizer_layer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01670a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формирование структуры вида: [слово]->[вектор]\n",
    "embeddings_new_index = {word: E_new[i] for i, word in enumerate(vectorizer_layer.get_vocabulary())}\n",
    "len(embeddings_new_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38310216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запрос\n",
    "q = embeddings_new_index['computer']\n",
    "\n",
    "# Вычисление косинусного сходства (дистанция от 0 до 1)\n",
    "S = 1 - cosine_similarity(E_new, np.array([q, ]))\n",
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5956ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список слова запросов\n",
    "query_words = [\n",
    "    ['computer']\n",
    "]\n",
    "\n",
    "n_top = 10  # топ-10 слов релевантных запросу\n",
    "\n",
    "W_top = np.empty((S.shape[1], n_top), dtype='object')\n",
    "\n",
    "for i in range(S.shape[1]):\n",
    "    \"\"\"\n",
    "    Удаляем из результата слова запроса и\n",
    "    сохраняем топ-n слов для каждого запроса\n",
    "    \"\"\"\n",
    "    # Фильтруем слова i-го запроса\n",
    "    mask = np.isin(words_new, query_words[i])\n",
    "    # Применяем фильтр, сортируем по близости и \n",
    "    # оставляем топ 10\n",
    "    W_top[i] = words_new[~mask][S[~mask, i].argsort()][:n_top]\n",
    "\n",
    "# Вывод в виде датафрейма\n",
    "pd.DataFrame(data=W_top.T, columns=[f\"q{i+1}\" for i in range(W_top.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7204762",
   "metadata": {},
   "source": [
    "## Источники"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e73ec8",
   "metadata": {},
   "source": [
    "- [Using pre-trained word embeddings](https://keras.io/examples/nlp/pretrained_word_embeddings/)\n",
    "- [GloVe: Global Vectors for Word Representation](https://github.com/stanfordnlp/GloVe)\n",
    "- [Pre-trained word vectors trained using fastText](https://fasttext.cc/docs/en/english-vectors.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
