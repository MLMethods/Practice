{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:18pt; padding-top:20px; text-align:center\">СЕМИНАР. <b>Кросс-валидация</b></div><hr>\n",
    "<div style=\"text-align:right;\">Папулин С.Ю. <span style=\"font-style: italic;font-weight: bold;\">(papulin.study@mail.ru)</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Содержание\n",
    "\n",
    "- [1. Подходы к разбиению исходных данных](#1.-Подходы-к-разбиению-исходных-данных)\n",
    "- [2. Оценка качества модели](#2.-Оценка-качества-модели)\n",
    "- [3. Выбор модели](#3.-Выбор-модели)\n",
    "- [4. Сетка гиперпараметров](#4.-Сетка-гиперпараметров)\n",
    "- [5. Вложенная кросс-валидация](#5.-Вложенная-кросс-валидация)\n",
    "- [6. Источники](#6.-Источники)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Подключение библиотек</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    ShuffleSplit,\n",
    "    KFold, \n",
    "    LeaveOneOut,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score, \n",
    "    cross_validate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подходы к разбиению исходных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отложенная выборка (Holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исходные данные\n",
    "x = np.array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
    "y = np.array([1, 1, 0, 0, 1, 0, 1, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделения данные на обучающее и тестовое множества\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=0)\n",
    "print(x_train, y_train)\n",
    "print(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Замечание: данный класс может быть использован в GridSearchCV \n",
    "# для реализации выбора параметров с отложенной выборкой\n",
    "splitter = ShuffleSplit(n_splits=1, test_size=0.3)\n",
    "splits = splitter.split(x)\n",
    "for train_index, test_index in splits:\n",
    "    print(train_index, test_index)\n",
    "    # print(x[train_index], x[test_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кросс-валидация K-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исходные данные\n",
    "x = np.array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
    "y = np.array([1, 1, 0, 0, 1, 0, 1, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Без тасовки\n",
    "kf = KFold(n_splits=3)\n",
    "splits = kf.split(x)\n",
    "for train_index, test_index in splits:\n",
    "    print(train_index, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# С тасовки\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "splits = kf.split(x)\n",
    "for train_index, test_index in splits:\n",
    "    print(train_index, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вывод сплитов\n",
    "splits = kf.split(x, y)\n",
    "for indx, (train_index, test_index) in enumerate(splits):\n",
    "    print(\"Split\", indx+1)\n",
    "    print(\"\\tTrain set\")\n",
    "    print(\"\\tx: {}\\n\\ty: {}\".format(x[train_index],  y[train_index]))\n",
    "    print(\"\\tTest set\")\n",
    "    print(\"\\tx: {}\\n\\ty: {}\\n\".format(x[test_index],  y[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тасовка и кросс-валидация\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "x_, y_ = shuffle(x, y)\n",
    "print(\"Initial x:\\t{}\\nShuffled x:\\t{}\".format(x, x_))\n",
    "print(\"Initial y:\\t{}\\nShuffled y:\\t{}\".format(y, y_))\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "splits = kf.split(x_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кросс-валидация Leave-One-Out (LOO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исходные данные\n",
    "x = np.array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
    "y = np.array([1, 1, 0, 0, 1, 0, 1, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo = LeaveOneOut()\n",
    "for train, test in loo.split(x):\n",
    "    print(\"{}{}\".format(train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стратифицированная выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
    "y = np.array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кросс-валидация с kfolds без тасовки\n",
    "kf = KFold(n_splits=3)\n",
    "splits = kf.split(x, y)\n",
    "i = 0\n",
    "for train_index, test_index in splits:\n",
    "    print(\"Split\", i+1)\n",
    "    print(\"\\tindices:\\t{}{}\".format(train_index, test_index))\n",
    "    print(\"\\ty:\\t\\t{}{}\".format(y[train_index], y[test_index]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Стратифицированная кросс-валидация с kfolds\n",
    "kf = StratifiedKFold(n_splits=3)\n",
    "splits = kf.split(x, y)\n",
    "i = 0\n",
    "for train_index, test_index in splits:\n",
    "    print(\"Split\", i+1)\n",
    "    print(\"\\tindices:\\t{}{}\".format(train_index, test_index))\n",
    "    print(\"\\ty:\\t\\t{}{}\".format(y[train_index], y[test_index]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Оценка качества модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_dataset(intercept=2, slope=0.3, n=100, start_x=4, length_x=8, mu=0, sigma=0.5):\n",
    "    f = lambda x: intercept + slope*x\n",
    "    x = stats.uniform.rvs(size=n, loc=start_x, scale=length_x)\n",
    "    e = stats.norm.rvs(size=n, loc=mu, scale=sigma)\n",
    "    y_true = f(x) + e\n",
    "    return x.reshape(-1,1), y_true, f\n",
    "\n",
    "# Генерация исходных данных\n",
    "X, y_true, f = regression_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# График\n",
    "xx = np.linspace(4, 12, 100)\n",
    "plt.title(\"Initial Data\")\n",
    "plt.scatter(X, y_true, color=\"green\", label=\"observed\")\n",
    "plt.plot(xx, f(xx), \"-\", color=\"SteelBlue\", label=\"true function\", zorder=1)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y_{true}$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPEATS = 10\n",
    "\n",
    "mses = np.full(REPEATS, np.inf)\n",
    "\n",
    "for i in range(REPEATS):\n",
    "\n",
    "    # Разбиение данных\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_true, \n",
    "        test_size=0.3, \n",
    "        random_state=i)\n",
    "\n",
    "    # Обучение\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Предсказания для тестового множества\n",
    "    y_test__pred = linear_model.predict(X_test)\n",
    "\n",
    "    # Ошибки на тестовом множестве\n",
    "    mses[i] = mean_squared_error(y_test, y_test__pred)\n",
    "    print(\"{}) Test MSE: {}\".format(i+1, mses[i]))\n",
    "\n",
    "print(\"\\nДоверительный интервал MSE: {:0.3f} +/- {:0.3f}\"\n",
    "      .format(mses.mean(), mses.std() * 2.0))\n",
    "\n",
    "# Построение диаграммы размаха\n",
    "holdout_mses = mses\n",
    "plt.figure()\n",
    "plt.scatter(np.full(len(holdout_mses), 1), holdout_mses, c=\"green\", alpha=0.5)\n",
    "plt.boxplot(holdout_mses, showmeans=True, labels=[\"holdout\", ],\n",
    "            meanprops=dict(markerfacecolor=\"orange\", markeredgecolor=\"black\"))\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPEATS = 10\n",
    "\n",
    "mses = np.full(REPEATS, np.inf)\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for i in range(REPEATS):\n",
    "    \n",
    "    kf.random_state = i\n",
    "    \n",
    "    # Обучение\n",
    "    mse_list = - cross_val_score(linear_model, X, y_true, cv=kf, \n",
    "                                 scoring=\"neg_mean_squared_error\")\n",
    "    \n",
    "     # Средняя ошибка на тестовом множестве\n",
    "    mses[i] = mse_list.mean()\n",
    "    print(\"{}) Test MSE: {}\".format(i+1,  mses[i]))\n",
    "    \n",
    "print(\"\\nДоверительный интервал MSE: {:0.3f} +/- {:0.3f}\".format(mses.mean(), mses.std() * 2.0))\n",
    "\n",
    "# Построение диаграммы размаха\n",
    "plt.figure()\n",
    "plt.scatter(np.full(len(mses), 1), mses, c=\"steelblue\", alpha=0.5)\n",
    "plt.boxplot(mses, showmeans=True, labels=[\"kfolds cv\", ],\n",
    "            meanprops=dict(markerfacecolor=\"orange\", markeredgecolor=\"black\"))\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравнение оценки качества модели с отложенной выборкой и кросс-валидацией с kfolds\n",
    "plt.figure()\n",
    "plt.title(\"holdout vs kfolds cv\")\n",
    "plt.scatter(np.full(len(holdout_mses), 1), holdout_mses, c=\"green\", alpha=0.5)\n",
    "plt.scatter(np.full(len(mses), 2), mses, c=\"steelblue\", alpha=0.5)\n",
    "plt.boxplot(np.c_[holdout_mses, mses], showmeans=True,\n",
    "            labels=[\"holdouts\", \"kfolds cv\"],\n",
    "            meanprops=dict(markerfacecolor=\"orange\", markeredgecolor=\"black\"))\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Выбор модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_dataset():\n",
    "    n = 200\n",
    "    x = stats.uniform.rvs(size=n, loc=0, scale=5, random_state=10)\n",
    "    f = lambda x:  np.sin(x)\n",
    "    y_true = stats.norm.rvs(size=n, loc=0, scale=0.4, random_state=10) + f(x)\n",
    "    return x.reshape(-1,1), y_true, f\n",
    "\n",
    "# Генерация исходных данных\n",
    "X, y_true, f = regression_dataset()\n",
    "\n",
    "# График\n",
    "xx = np.linspace(0, 5, 100)\n",
    "plt.title(\"Initial Data\")\n",
    "plt.scatter(X, y_true, color=\"green\", label=\"observed\")\n",
    "plt.plot(xx, f(xx), \"-\", color=\"SteelBlue\", label=\"true function\", zorder=1)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y_{true}$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 12345\n",
    "SPLITS = 5\n",
    "MAX_DEGREE = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант 1\n",
    "\n",
    "Замечание: Важно, чтобы сплиты `KFold` были одинаковыми для всех степеней. Поэтому далее используется `random_state`. Либо можно перетасовать данные перед кросс-валидацией и установить `shuffle` равным `False` для `KFold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиение данных на обучающее и тестовое множества\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_true, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "# Инициализация делителя для кросс-валидации\n",
    "# Замечание: нет необходимости использовать shuffle, т.к. train_test_split\n",
    "# выполняет тасовку\n",
    "kf = KFold(n_splits=SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Степени полинома\n",
    "degrees = list(range(1, MAX_DEGREE+1))\n",
    "\n",
    "best_degree = 0\n",
    "best_mse = float(\"inf\")\n",
    "\n",
    "# Замечание: будем использовать один экземпляр и менять степень;\n",
    "#  каждый раз модель будет заново обучаться; можно и каждый раз\n",
    "#  создавать отдельный экземпляр\n",
    "pipeline = Pipeline([\n",
    "    (\"transformation\", PolynomialFeatures(degree=None, include_bias=False)), \n",
    "    (\"linear_model\", LinearRegression(fit_intercept=True))\n",
    "])\n",
    "\n",
    "# Выбор степени с наименьшей валидационной ошибкой \n",
    "for indx, degree in enumerate(degrees):\n",
    "    # Обучение с кросс-валидацией\n",
    "    pipeline.named_steps[\"transformation\"].degree = degree\n",
    "    scores = cross_validate(\n",
    "        pipeline, X_train, y_train, cv=kf, \n",
    "        scoring=[\"neg_mean_squared_error\",],\n",
    "        return_train_score=True\n",
    "    )\n",
    "    # Средняя ошибка на проверочном множестве\n",
    "    mse_avg = -scores[\"test_neg_mean_squared_error\"].mean()\n",
    "    # Выбор лучшего гиперпараметра\n",
    "    if best_mse > mse_avg:\n",
    "        best_mse = mse_avg\n",
    "        best_degree = degree\n",
    "    print(\"{}) Val MSE for degree {}: {}\".format(indx+1, degree, mse_avg))\n",
    "\n",
    "print(\"Best degree:\", best_degree)\n",
    "\n",
    "# Повторное обучение на всем обучающем множестве \n",
    "pipeline.named_steps[\"transformation\"].degree = best_degree\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания для тестового множества\n",
    "y_test__pred = pipeline.predict(X_test)\n",
    "\n",
    "# Ошибки на тестовом множестве\n",
    "mse_test = mean_squared_error(y_test, y_test__pred)\n",
    "\n",
    "print(\"Тестовое множество:\")\n",
    "print(\"\\tTest MSE:\", mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиение данных на обучающее и тестовое множества\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_true, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "# Инициализация делителя для кросс-валидации\n",
    "kf = KFold(n_splits=SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Степени полинома\n",
    "degrees = list(range(1, MAX_DEGREE+1))\n",
    "\n",
    "# Инициализация массива для MSE\n",
    "scores = np.zeros((MAX_DEGREE, SPLITS))\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"transformation\", PolynomialFeatures(degree=None, include_bias=False)), \n",
    "    (\"linear_model\", LinearRegression(fit_intercept=True))\n",
    "])\n",
    "\n",
    "# Обучение\n",
    "for i, (train_index, val_index) in enumerate(kf.split(X_train, y_train)):\n",
    "    for j, degree in enumerate(degrees):\n",
    "        pipeline.named_steps[\"transformation\"].degree = degree\n",
    "        pipeline.fit(X_train[train_index], y_train[train_index])\n",
    "        scores[j, i] = mean_squared_error(\n",
    "            y_train[val_index], \n",
    "            pipeline.predict(X_train[val_index]))\n",
    "\n",
    "# Средние проверочные ошибки для каждой степени\n",
    "mses_avg = scores.mean(axis=1)\n",
    "\n",
    "for indx, mse_avg in enumerate(mses_avg):\n",
    "    print(\"{}) Val MSE for degree {}: {}\".format(indx+1, degrees[indx], mse_avg))\n",
    "\n",
    "indx_min__mse_avg = mses_avg.argmin()\n",
    "best_degree = degrees[indx_min__mse_avg]\n",
    "\n",
    "print(\"Best degree:\", best_degree)\n",
    "\n",
    "# Повторное обучение на всем обучающем множестве \n",
    "pipeline.named_steps[\"transformation\"].degree = best_degree\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания для тестового множества\n",
    "y_test__pred = pipeline.predict(X_test)\n",
    "\n",
    "# Ошибки на тестовом множестве\n",
    "mse_test = mean_squared_error(y_test, y_test__pred)\n",
    "\n",
    "print(\"Тестовое множество:\")\n",
    "print(\"\\tTest MSE:\", mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_on_split(train_index, val_index, max_degree=MAX_DEGREE):\n",
    "    pipeline = Pipeline([\n",
    "        (\"transformation\", PolynomialFeatures(degree=None, include_bias=False)), \n",
    "        (\"linear_model\", LinearRegression(fit_intercept=True))\n",
    "    ])\n",
    "    degrees = list(range(1, MAX_DEGREE+1))\n",
    "    scores = np.zeros(max_degree)\n",
    "    for j, degree in enumerate(degrees):\n",
    "        pipeline.named_steps[\"transformation\"].degree = degree\n",
    "        pipeline.fit(X_train[train_index], y_train[train_index])\n",
    "        scores[j] = mean_squared_error(\n",
    "            y_train[val_index], \n",
    "            pipeline.predict(X_train[val_index]))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиение данных на обучающее и тестовое множества\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_true, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "# Инициализация делителя для кросс-валидации\n",
    "kf = KFold(n_splits=SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Инициализация массива для MSE\n",
    "scores = list()\n",
    "\n",
    "# Параллельное обучение по сплитам\n",
    "parallel = Parallel(n_jobs=4)\n",
    "func = delayed(scores_on_split)\n",
    "scores = np.asarray(\n",
    "    parallel(\n",
    "        func(train_index, val_index) \n",
    "        for train_index, val_index in kf.split(X_train, y_train)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Средние проверочные ошибки для каждой степени\n",
    "mses_avg = scores.mean(axis=0)\n",
    "\n",
    "for indx, mse_avg in enumerate(mses_avg):\n",
    "    print(\"{}) Val MSE for degree {}: {}\".format(indx+1, degrees[indx], mse_avg))\n",
    "\n",
    "indx_min__mse_avg = mses_avg.argmin()\n",
    "best_degree = degrees[indx_min__mse_avg]\n",
    "\n",
    "print(\"Best degree:\", best_degree)\n",
    "\n",
    "# Повторное обучение на всем обучающем множестве \n",
    "pipeline.named_steps[\"transformation\"].degree = best_degree\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания для тестового множества\n",
    "y_test__pred = pipeline.predict(X_test)\n",
    "\n",
    "# Ошибки на тестовом множестве\n",
    "mse_test = mean_squared_error(y_test, y_test__pred)\n",
    "\n",
    "print(\"Тестовое множество:\")\n",
    "print(\"\\tTest MSE:\", mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Сетка гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиение данных на обучающее и тестовое множества\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_true, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "# Инициализация делителя для кросс-валидации\n",
    "kf = KFold(n_splits=SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Степени полинома\n",
    "degrees = list(range(1, MAX_DEGREE+1))\n",
    "\n",
    "# Инициализация массива для MSE\n",
    "scores = np.zeros((MAX_DEGREE, SPLITS))\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"transformation\", PolynomialFeatures(degree=None, include_bias=False)), \n",
    "    (\"linear_model\", LinearRegression(fit_intercept=True))\n",
    "])\n",
    "\n",
    "# Сетка параметров\n",
    "parameters = {\n",
    "    \"transformation__degree\": degrees,\n",
    "}\n",
    "\n",
    "# Параметры обучения\n",
    "grid_class_parameters = {\n",
    "    \"estimator\": pipeline,\n",
    "    \"param_grid\": parameters,\n",
    "    \"cv\": kf,\n",
    "    \"scoring\": \"neg_mean_squared_error\"\n",
    "}\n",
    "\n",
    "# Обучение\n",
    "grid_search = GridSearchCV(**grid_class_parameters)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Средние проверочные ошибки для каждой степени\n",
    "mses_avg = np.abs(grid_search.cv_results_[\"mean_test_score\"])\n",
    "\n",
    "for indx, mse_avg in enumerate(mses_avg):\n",
    "    print(\"{}) Val MSE for degree {}: {}\".format(indx+1, degrees[indx], mse_avg))\n",
    "\n",
    "print(\"Best degree:\", grid_search.best_params_[\"transformation__degree\"])\n",
    "\n",
    "# Предсказания для тестового множества\n",
    "y_test__pred = grid_search.predict(X_test)\n",
    "\n",
    "# Ошибки на тестовом множестве\n",
    "mse_test = mean_squared_error(y_test, y_test__pred)\n",
    "\n",
    "print(\"Тестовое множество:\")\n",
    "print(\"\\tTest MSE:\", mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Закон распределения \n",
    "# Дискретное равномерное распределение (выборка с возвращением)\n",
    "degree_rv = randint(low=1, high=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = {\n",
    "    'transformation__degree': degree_rv,\n",
    "}\n",
    "rand_search = RandomizedSearchCV(\n",
    "    estimator=pipeline, \n",
    "    param_distributions=distributions,\n",
    "    n_iter=5,\n",
    "    cv=kf,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "rand_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средние проверочные ошибки для каждой степени\n",
    "mses_avg = np.abs(grid_search.cv_results_[\"mean_test_score\"])\n",
    "\n",
    "for indx, mse_avg in enumerate(mses_avg):\n",
    "    print(\"{}) Val MSE for degree {}: {}\".format(indx+1, degrees[indx], mse_avg))\n",
    "\n",
    "print(\"Best degree:\", rand_search.best_params_[\"transformation__degree\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rand_search.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "-rand_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказания для тестового множества\n",
    "y_test__pred = rand_search.predict(X_test)\n",
    "\n",
    "# Ошибки на тестовом множестве\n",
    "mse_test = mean_squared_error(y_test, y_test__pred)\n",
    "\n",
    "print(\"Тестовое множество:\")\n",
    "print(\"\\tTest MSE:\", mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Вложенная кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка качества модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполним тасовку данных\n",
    "X, y_true = shuffle(X, y_true, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество сплитов для внешней кросс-валидации\n",
    "OUTER_SPLITS = 5\n",
    "# Количество сплитов для внутренней кросс-валидации\n",
    "INNER_STPLITS = 3\n",
    "\n",
    "# Степени полинома (гиперпараметр)\n",
    "degrees = list(range(1, MAX_DEGREE+1))\n",
    "\n",
    "# Инициализация массива для MSE\n",
    "outer_scores = np.zeros(OUTER_SPLITS)\n",
    "inner_scores = np.zeros((MAX_DEGREE, INNER_STPLITS))\n",
    "\n",
    "# Модель с гиперпараметрами\n",
    "pipeline = Pipeline([\n",
    "    (\"transformation\", PolynomialFeatures(degree=None, include_bias=False)), \n",
    "    (\"linear_model\", LinearRegression(fit_intercept=True))\n",
    "])\n",
    "\n",
    "# Делитель данных для внешней и внутренней кросс-валидации\n",
    "outer_kf = KFold(n_splits=OUTER_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "inner_kf = KFold(n_splits=INNER_STPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Внешняя кросс-валидация\n",
    "for i, (trainval_index, test_index) in enumerate(outer_kf.split(X, y_true)):\n",
    "    # Внутренняя кросс-валидация\n",
    "    for j, (train_index, val_index) in enumerate(inner_kf.split(X[trainval_index], y_true[trainval_index])):\n",
    "        for k, degree in enumerate(degrees):\n",
    "            pipeline.named_steps[\"transformation\"].degree = degree\n",
    "            pipeline.fit(X[trainval_index][train_index], y_true[trainval_index][train_index])\n",
    "            inner_scores[k, j] = mean_squared_error(\n",
    "                y_true=y_true[trainval_index][val_index], \n",
    "                y_pred=pipeline.predict(X[trainval_index][val_index])\n",
    "            )\n",
    "    # Выбор гиперпараметра\n",
    "    best_inner_degree = degrees[inner_scores.mean(axis=1).argmin()]\n",
    "    # Повторное обучение на всем trainval\n",
    "    pipeline.named_steps[\"transformation\"].degree = best_inner_degree\n",
    "    pipeline.fit(X[trainval_index], y_true[trainval_index])\n",
    "    # Тестовая ошибка\n",
    "    outer_scores[i] = mean_squared_error(\n",
    "        y_true=y_true[test_index], \n",
    "        y_pred=pipeline.predict(X[test_index])\n",
    "    )\n",
    "    print(f'Test MSE for outer split {i}: {outer_scores[i]:.4f}\\tBest degree: {best_inner_degree}')\n",
    "\n",
    "# Ошибки на тестовом множестве (среднее по сплитам)\n",
    "mse_test = outer_scores.mean()\n",
    "\n",
    "print(\"Оценка ошибки тестирования:\")\n",
    "print(\"\\tTest MSE:\", mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сетка гиперпараметров\n",
    "param_grid = { \"transformation__degree\": degrees, }\n",
    "\n",
    "# Обучение\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=inner_kf,\n",
    "    scoring=\"neg_mean_squared_error\"\n",
    ")\n",
    "\n",
    "# Вложенная кросс-валидация\n",
    "scores = cross_validate(\n",
    "    grid_search, X, y_true, cv=outer_kf, \n",
    "    scoring=[\"neg_mean_squared_error\",]\n",
    ")\n",
    "\n",
    "mse_test = -scores['test_neg_mean_squared_error'].mean()\n",
    "\n",
    "print(\"Оценка ошибки тестирования:\")\n",
    "print(\"\\tTest MSE:\", mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация массива для MSE\n",
    "scores = np.zeros((MAX_DEGREE, OUTER_SPLITS))\n",
    "for i, (trainval_index, test_index) in enumerate(outer_kf.split(X, y_true)):\n",
    "    for k, degree in enumerate(degrees):\n",
    "        pipeline.named_steps[\"transformation\"].degree = degree\n",
    "        pipeline.fit(X[trainval_index], y_true[trainval_index])\n",
    "        scores[k, i] = mean_squared_error(\n",
    "            y_true=y_true[test_index], \n",
    "            y_pred=pipeline.predict(X[test_index])\n",
    "        )\n",
    "best_mse = scores.mean(axis=1).min()\n",
    "best_degree = degrees[scores.mean(axis=1).argmin()]\n",
    "print(f'Best hyperparameter: {best_degree}\\tMSE: {best_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "# Обучение на всем наборе данных\n",
    "best_pipeline = clone(pipeline)\n",
    "best_pipeline.named_steps[\"transformation\"].degree = best_degree\n",
    "best_pipeline.fit(X[trainval_index], y_true[trainval_index])\n",
    "\n",
    "# Модель для предсказания\n",
    "best_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=outer_kf,\n",
    "    scoring=\"neg_mean_squared_error\"\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mse = -grid_search.best_score_\n",
    "best_degree = grid_search.best_params_['transformation__degree']\n",
    "\n",
    "print(f'Best hyperparameter: {best_degree}\\tMSE: {best_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель для предсказания\n",
    "grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Источники"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Sklearn: Cross-validation: evaluating estimator performance](http://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "- [Model selection done right: A gentle introduction to nested cross-validation](https://ploomber.io/blog/nested-cv/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
