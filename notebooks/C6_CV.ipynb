{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:18pt; padding-top:20px; text-align:center\">СЕМИНАР. <b>Кросс-валидация</b></div><hr>\n",
    "<div style=\"text-align:right;\">Папулин С.Ю. <span style=\"font-style: italic;font-weight: bold;\">(papulin.study@mail.ru)</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"0\"></a>\n",
    "<div><span style=\"font-size:14pt; font-weight:bold\">Содержание</span>\n",
    "    <ol>\n",
    "        <li><a href=\"#1\">Подходы к разбиению исходных данных</a></li>\n",
    "        <li><a href=\"#2\">Оценка качества модели</a>\n",
    "        <li><a href=\"#3\">Выбор модели с кросс-валидацией</a></li>\n",
    "        <li><a href=\"#4\">Источники</a>\n",
    "        </li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Подключение библиотек</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    ShuffleSplit,\n",
    "    KFold, \n",
    "    LeaveOneOut,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score, \n",
    "    cross_validate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:16pt; font-weight:bold\">1. Подходы к разбиению исходных данных</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отложенная выборка (Holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исходные данные\n",
    "x = np.array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
    "y = np.array([1, 1, 0, 0, 1, 0, 1, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделения данные на обучающее и тестовое множества\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=0)\n",
    "print(x_train, y_train)\n",
    "print(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Замечание: данный класс может быть использован в GridSearchCV \n",
    "# для реализации выбора параметров с отложенной выборкой\n",
    "splitter = ShuffleSplit(n_splits=1, test_size=0.3)\n",
    "splits = splitter.split(x)\n",
    "for train_index, test_index in splits:\n",
    "    print(train_index, test_index)\n",
    "    # print(x[train_index], x[test_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кросс-валидация K-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исходные данные\n",
    "x = np.array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
    "y = np.array([1, 1, 0, 0, 1, 0, 1, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Без тасовки\n",
    "kf = KFold(n_splits=3)\n",
    "splits = kf.split(x)\n",
    "for train_index, test_index in splits:\n",
    "    print(train_index, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# С тасовки\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "splits = kf.split(x)\n",
    "for train_index, test_index in splits:\n",
    "    print(train_index, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вывод сплитов\n",
    "splits = kf.split(x, y)\n",
    "for indx, (train_index, test_index) in enumerate(splits):\n",
    "    print(\"Split\", indx+1)\n",
    "    print(\"\\tTrain set\")\n",
    "    print(\"\\tx: {}\\n\\ty: {}\".format(x[train_index],  y[train_index]))\n",
    "    print(\"\\tTest set\")\n",
    "    print(\"\\tx: {}\\n\\ty: {}\\n\".format(x[test_index],  y[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тасовка и кросс-валидация\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "x_, y_ = shuffle(x, y)\n",
    "print(\"Initial x:\\t{}\\nShuffled x:\\t{}\".format(x, x_))\n",
    "print(\"Initial y:\\t{}\\nShuffled y:\\t{}\".format(y, y_))\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "splits = kf.split(x_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кросс-валидация Leave-One-Out (LOO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исходные данные\n",
    "x = np.array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
    "y = np.array([1, 1, 0, 0, 1, 0, 1, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo = LeaveOneOut()\n",
    "for train, test in loo.split(x):\n",
    "    print(\"{}{}\".format(train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стратифицированная выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
    "y = np.array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кросс-валидация с kfolds без тасовки\n",
    "kf = KFold(n_splits=3)\n",
    "splits = kf.split(x, y)\n",
    "i = 0\n",
    "for train_index, test_index in splits:\n",
    "    print(\"Split\", i+1)\n",
    "    print(\"\\tindices:\\t{}{}\".format(train_index, test_index))\n",
    "    print(\"\\ty:\\t\\t{}{}\".format(y[train_index], y[test_index]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Стратифицированная кросс-валидация с kfolds\n",
    "kf = StratifiedKFold(n_splits=3)\n",
    "splits = kf.split(x, y)\n",
    "i = 0\n",
    "for train_index, test_index in splits:\n",
    "    print(\"Split\", i+1)\n",
    "    print(\"\\tindices:\\t{}{}\".format(train_index, test_index))\n",
    "    print(\"\\ty:\\t\\t{}{}\".format(y[train_index], y[test_index]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:16pt; font-weight:bold\">2. Оценка качества модели</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_dataset(intercept=2, slope=0.3, n=100, start_x=4, length_x=8, mu=0, sigma=0.5):\n",
    "    f = lambda x: intercept + slope*x\n",
    "    x = stats.uniform.rvs(size=n, loc=start_x, scale=length_x)\n",
    "    e = stats.norm.rvs(size=n, loc=mu, scale=sigma)\n",
    "    y_true = f(x) + e\n",
    "    return x.reshape(-1,1), y_true, f\n",
    "\n",
    "# Генерация исходных данных\n",
    "X, y_true, f = regression_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# График\n",
    "xx = np.linspace(4, 12, 100)\n",
    "plt.title(\"Initial Data\")\n",
    "plt.scatter(X, y_true, color=\"green\", label=\"observed\")\n",
    "plt.plot(xx, f(xx), \"-\", color=\"SteelBlue\", label=\"true function\", zorder=1)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y_{true}$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPEATS = 10\n",
    "\n",
    "mses = np.full(REPEATS, np.inf)\n",
    "\n",
    "for i in range(REPEATS):\n",
    "\n",
    "    # Разбиение данных\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_true, \n",
    "        test_size=0.3, \n",
    "        random_state=i)\n",
    "\n",
    "    # Обучение\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Предсказания для тестового множества\n",
    "    y_test__pred = linear_model.predict(X_test)\n",
    "\n",
    "    # Ошибки на тестовом множестве\n",
    "    mses[i] = mean_squared_error(y_test, y_test__pred)\n",
    "    print(\"{}) Test MSE: {}\".format(i+1, mses[i]))\n",
    "\n",
    "print(\"\\nДоверительный интервал MSE: {:0.3f} +/- {:0.3f}\"\n",
    "      .format(mses.mean(), mses.std() * 2.0))\n",
    "\n",
    "# Построение диаграммы размаха\n",
    "holdout_mses = mses\n",
    "plt.figure()\n",
    "plt.scatter(np.full(len(holdout_mses), 1), holdout_mses, c=\"green\", alpha=0.5)\n",
    "plt.boxplot(holdout_mses, showmeans=True, labels=[\"holdout\", ],\n",
    "            meanprops=dict(markerfacecolor=\"orange\", markeredgecolor=\"black\"))\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPEATS = 10\n",
    "\n",
    "mses = np.full(REPEATS, np.inf)\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for i in range(REPEATS):\n",
    "    \n",
    "    kf.random_state = i\n",
    "    \n",
    "    # Обучение\n",
    "    mse_list = - cross_val_score(linear_model, X, y_true, cv=kf, \n",
    "                                 scoring=\"neg_mean_squared_error\")\n",
    "    \n",
    "     # Средняя ошибка на тестовом множестве\n",
    "    mses[i] = mse_list.mean()\n",
    "    print(\"{}) Test MSE: {}\".format(i+1,  mses[i]))\n",
    "    \n",
    "print(\"\\nДоверительный интервал MSE: {:0.3f} +/- {:0.3f}\".format(mses.mean(), mses.std() * 2.0))\n",
    "\n",
    "# Построение диаграммы размаха\n",
    "plt.figure()\n",
    "plt.scatter(np.full(len(mses), 1), mses, c=\"steelblue\", alpha=0.5)\n",
    "plt.boxplot(mses, showmeans=True, labels=[\"kfolds cv\", ],\n",
    "            meanprops=dict(markerfacecolor=\"orange\", markeredgecolor=\"black\"))\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравнение оценки качества модели с отложенной выборкой и кросс-валидацией с kfolds\n",
    "plt.figure()\n",
    "plt.title(\"holdout vs kfolds cv\")\n",
    "plt.scatter(np.full(len(holdout_mses), 1), holdout_mses, c=\"green\", alpha=0.5)\n",
    "plt.scatter(np.full(len(mses), 2), mses, c=\"steelblue\", alpha=0.5)\n",
    "plt.boxplot(np.c_[holdout_mses, mses], showmeans=True,\n",
    "            labels=[\"holdouts\", \"kfolds cv\"],\n",
    "            meanprops=dict(markerfacecolor=\"orange\", markeredgecolor=\"black\"))\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:16pt; font-weight:bold\">3. Выбор модели с кросс-валидацией</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_dataset():\n",
    "    n = 100\n",
    "    x = stats.uniform.rvs(size=n, loc=0, scale=5, random_state=10)\n",
    "    f = lambda x:  np.sin(x)\n",
    "    y_true = stats.norm.rvs(size=n, loc=0, scale=0.2, random_state=10) + f(x)\n",
    "    return x.reshape(-1,1), y_true, f\n",
    "\n",
    "# Генерация исходных данных\n",
    "X, y_true, f = regression_dataset()\n",
    "\n",
    "# График\n",
    "xx = np.linspace(0, 5, 100)\n",
    "plt.title(\"Initial Data\")\n",
    "plt.scatter(X, y_true, color=\"green\", label=\"observed\")\n",
    "plt.plot(xx, f(xx), \"-\", color=\"SteelBlue\", label=\"true function\", zorder=1)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y_{true}$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLITS = 5\n",
    "MAX_DEGREE = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант 1\n",
    "\n",
    "Замечание: Важно, чтобы сплиты `KFold` были одинаковыми для всех степеней. Поэтому далее используется `random_state`. Либо можно перетасовать данные перед кросс-валидацией и установить `shuffle` равным `False` для `KFold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиение данных на обучающее и тестовое множества\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_true, test_size=0.3, random_state=200)\n",
    "\n",
    "# Инициализация делителя для кросс-валидации\n",
    "# Замечание: нет необходимости использовать shuffle, т.к. train_test_split\n",
    "# выполняет тасовку\n",
    "kf = KFold(n_splits=SPLITS, shuffle=True, random_state=12345)\n",
    "\n",
    "# Степени полинома\n",
    "degrees = list(range(1, MAX_DEGREE+1))\n",
    "\n",
    "best_degree = 0\n",
    "best_mse = float(\"inf\")\n",
    "\n",
    "# Замечание: будем использовать один экземпляр и менять степень;\n",
    "#  каждый раз модель будет заново обучаться; можно и каждый раз\n",
    "#  создавать отдельный экземпляр\n",
    "pipeline = Pipeline([\n",
    "    (\"transformation\", PolynomialFeatures(degree=None, include_bias=False)), \n",
    "    (\"linear_model\", LinearRegression(fit_intercept=True))\n",
    "])\n",
    "\n",
    "\n",
    "# Выбор степени с наименьшей валидационной ошибкой \n",
    "for indx, degree in enumerate(degrees):\n",
    "\n",
    "    pipeline.named_steps[\"transformation\"].degree = degree\n",
    "    scores = cross_validate(\n",
    "        pipeline, X_train, y_train, cv=kf, \n",
    "        scoring=[\"neg_mean_squared_error\",],\n",
    "        return_train_score=True\n",
    "    )\n",
    "    \n",
    "    # Средняя ошибка на проверочном множестве\n",
    "    mse_avg = -scores[\"test_neg_mean_squared_error\"].mean()\n",
    "    \n",
    "    if best_mse > mse_avg:\n",
    "        best_mse = mse_avg\n",
    "        best_degree = degree\n",
    "    \n",
    "    print(\"{}) Test MSE for degree {}: {}\".format(indx+1, degree, mse_avg))\n",
    "\n",
    "print(\"Best degree:\", best_degree)\n",
    "\n",
    "# Повторное обучение на всем обучающем множестве \n",
    "pipeline.named_steps[\"transformation\"].degree = best_degree\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания для тестового множества\n",
    "y_test__pred = pipeline.predict(X_test)\n",
    "\n",
    "# Ошибки на тестовом множестве\n",
    "mse_test = mean_squared_error(y_test, y_test__pred)\n",
    "\n",
    "print(\"Тестовое множество:\")\n",
    "print(\"\\tTest MSE:\", mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиение данных на обучающее и тестовое множества\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_true, test_size=0.3, random_state=200)\n",
    "\n",
    "# Инициализация делителя для кросс-валидации\n",
    "kf = KFold(n_splits=SPLITS, shuffle=True, random_state=12345)\n",
    "\n",
    "# Степени полинома\n",
    "degrees = list(range(1, MAX_DEGREE+1))\n",
    "\n",
    "# Инициализация массива для MSE\n",
    "scores = np.zeros((MAX_DEGREE, SPLITS))\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"transformation\", PolynomialFeatures(degree=None, include_bias=False)), \n",
    "    (\"linear_model\", LinearRegression(fit_intercept=True))\n",
    "])\n",
    "\n",
    "# Обучение\n",
    "for i, (train_index, val_index) in enumerate(kf.split(X_train, y_train)):\n",
    "    for j, degree in enumerate(degrees):\n",
    "        pipeline.named_steps[\"transformation\"].degree = degree\n",
    "        pipeline.fit(X_train[train_index], y_train[train_index])\n",
    "        scores[j, i] = mean_squared_error(\n",
    "            y_train[val_index], \n",
    "            pipeline.predict(X_train[val_index]))\n",
    "\n",
    "# Средние проверочные ошибки для каждой степени\n",
    "mses_avg = scores.mean(axis=1)\n",
    "\n",
    "for indx, mse_avg in enumerate(mses_avg):\n",
    "    print(\"{}) Test MSE for degree {}: {}\".format(indx+1, degrees[indx], mse_avg))\n",
    "\n",
    "indx_min__mse_avg = mses_avg.argmin()\n",
    "best_degree = degrees[indx_min__mse_avg]\n",
    "\n",
    "print(\"Best degree:\", best_degree)\n",
    "\n",
    "# Повторное обучение на всем обучающем множестве \n",
    "pipeline.named_steps[\"transformation\"].degree = best_degree\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания для тестового множества\n",
    "y_test__pred = pipeline.predict(X_test)\n",
    "\n",
    "# Ошибки на тестовом множестве\n",
    "mse_test = mean_squared_error(y_test, y_test__pred)\n",
    "\n",
    "print(\"Тестовое множество:\")\n",
    "print(\"\\tTest MSE:\", mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_on_split(train_index, val_index, max_degree=MAX_DEGREE):\n",
    "    pipeline = Pipeline([\n",
    "        (\"transformation\", PolynomialFeatures(degree=None, include_bias=False)), \n",
    "        (\"linear_model\", LinearRegression(fit_intercept=True))\n",
    "    ])\n",
    "    degrees = list(range(1, MAX_DEGREE+1))\n",
    "    scores = np.zeros(max_degree)\n",
    "    for j, degree in enumerate(degrees):\n",
    "        pipeline.named_steps[\"transformation\"].degree = degree\n",
    "        pipeline.fit(X_train[train_index], y_train[train_index])\n",
    "        scores[j] = mean_squared_error(\n",
    "            y_train[val_index], \n",
    "            pipeline.predict(X_train[val_index]))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиение данных на обучающее и тестовое множества\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_true, test_size=0.3, random_state=200)\n",
    "\n",
    "# Инициализация делителя для кросс-валидации\n",
    "kf = KFold(n_splits=SPLITS, shuffle=True, random_state=12345)\n",
    "\n",
    "# Инициализация массива для MSE\n",
    "scores = list()\n",
    "\n",
    "# Параллельное обучение по сплитам\n",
    "parallel = Parallel(n_jobs=4)\n",
    "func = delayed(scores_on_split)\n",
    "scores = np.asarray(\n",
    "    parallel(\n",
    "        func(train_index, val_index) \n",
    "        for train_index, val_index in kf.split(X_train, y_train)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Средние проверочные ошибки для каждой степени\n",
    "mses_avg = scores.mean(axis=0)\n",
    "\n",
    "for indx, mse_avg in enumerate(mses_avg):\n",
    "    print(\"{}) Test MSE for degree {}: {}\".format(indx+1, degrees[indx], mse_avg))\n",
    "\n",
    "indx_min__mse_avg = mses_avg.argmin()\n",
    "best_degree = degrees[indx_min__mse_avg]\n",
    "\n",
    "print(\"Best degree:\", best_degree)\n",
    "\n",
    "# Повторное обучение на всем обучающем множестве \n",
    "pipeline.named_steps[\"transformation\"].degree = best_degree\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания для тестового множества\n",
    "y_test__pred = pipeline.predict(X_test)\n",
    "\n",
    "# Ошибки на тестовом множестве\n",
    "mse_test = mean_squared_error(y_test, y_test__pred)\n",
    "\n",
    "print(\"Тестовое множество:\")\n",
    "print(\"\\tTest MSE:\", mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиение данных на обучающее и тестовое множества\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_true, test_size=0.3, random_state=200)\n",
    "\n",
    "# Инициализация делителя для кросс-валидации\n",
    "kf = KFold(n_splits=SPLITS, shuffle=True, random_state=12345)\n",
    "\n",
    "# Степени полинома\n",
    "degrees = list(range(1, MAX_DEGREE+1))\n",
    "\n",
    "# Инициализация массива для MSE\n",
    "scores = np.zeros((MAX_DEGREE, SPLITS))\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"transformation\", PolynomialFeatures(degree=None, include_bias=False)), \n",
    "    (\"linear_model\", LinearRegression(fit_intercept=True))\n",
    "])\n",
    "\n",
    "# Сетка параметров\n",
    "parameters = {\n",
    "    \"transformation__degree\": degrees,\n",
    "}\n",
    "\n",
    "# Параметры обучения\n",
    "grid_class_parameters = {\n",
    "    \"estimator\": pipeline,\n",
    "    \"param_grid\": parameters,\n",
    "    \"cv\": kf,\n",
    "    \"scoring\": \"neg_mean_squared_error\"\n",
    "}\n",
    "\n",
    "# Обучение\n",
    "grid_search = GridSearchCV(**grid_class_parameters)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Средние проверочные ошибки для каждой степени\n",
    "mses_avg = np.abs(grid_search.cv_results_[\"mean_test_score\"])\n",
    "\n",
    "for indx, mse_avg in enumerate(mses_avg):\n",
    "    print(\"{}) Test MSE for degree {}: {}\".format(indx+1, degrees[indx], mse_avg))\n",
    "\n",
    "print(\"Best degree:\", grid_search.best_params_[\"transformation__degree\"])\n",
    "\n",
    "# Предсказания для тестового множества\n",
    "y_test__pred = grid_search.predict(X_test)\n",
    "\n",
    "# Ошибки на тестовом множестве\n",
    "mse_test = mean_squared_error(y_test, y_test__pred)\n",
    "\n",
    "print(\"Тестовое множество:\")\n",
    "print(\"\\tTest MSE:\", mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:16pt; font-weight:bold\">4. Источники</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://scikit-learn.org/stable/modules/cross_validation.html\">3.1. Cross-validation: evaluating estimator performance</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}