{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Распознавание языка текста\n",
    "\n",
    "<hr>\n",
    "\n",
    "С.Ю. Папулин (papulin.study@yandex.ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Содержание\n",
    "\n",
    "- [Статический текст](#Статический-текст)\n",
    "- [Динамический текст](#Динамический-текст)\n",
    "    - [Построение модели](#Построение-модели)\n",
    "    - [Проверка динамического распознавания](#Проверка-динамического-распознавания)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключение библиотек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../lib/\")\n",
    "from datasets import fetch_20languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Статический текст"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Набор данных](https://huggingface.co/datasets/papluca/language-identification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "dataset = fetch_20languages(return_X_y=True)\n",
    "\n",
    "# Вывод описания\n",
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = dataset.data['train']\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import get_data_home\n",
    "\n",
    "# # Директория по умолчанию, где хранятся данных\n",
    "# get_data_home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество текстов по каждому классу\n",
    "df_train['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Среднее количество символов в текстах по каждому классу\n",
    "df_train.groupby('labels')['text'].agg(\n",
    "    lambda text: text.str.len().mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(df_train['text'], df_train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = dataset.data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(df_test['text'], df_test['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Динамический текст"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Исходные данные\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаблон для делителя строки на слова\n",
    "COMPILER = re.compile(\"\\W+\", re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentence(lang, text):\n",
    "    for word in set(COMPILER.split(text)):\n",
    "        if word:\n",
    "            yield (lang, word)\n",
    "\n",
    "\n",
    "def sentence_flat_map(df):\n",
    "    def fetch_word_lang_pair():\n",
    "        for i, row in df.iterrows():\n",
    "            for item in split_sentence(row['labels'], row['text']):\n",
    "                yield item\n",
    "    return pd.DataFrame(\n",
    "        data=fetch_word_lang_pair(), \n",
    "        columns=['labels', 'word']\n",
    "    ).drop_duplicates()\n",
    "\n",
    "\n",
    "# Формивание датафрейма язык-слово и удаление повторений\n",
    "df_train_new = sentence_flat_map(df_train)\n",
    "df_test_new = sentence_flat_map(df_test)\n",
    "\n",
    "df_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = 'обуч'\n",
    "\n",
    "print(\n",
    "    df_train_new[df_train_new['word'].str.contains(INPUT)]\\\n",
    "        .groupby('labels')\\\n",
    "        .count().T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Априорные вероятности классов\n",
    "# class_prior=[\n",
    "#     0.04, 0.04, 0.05, 0.05, 0.1, 0.05, 0.05, 0.04, 0.05, 0.05,\n",
    "#     0.05, 0.05, 0.05, 0.05, 0.05, 0.04, 0.04, 0.05, 0.05, 0.05\n",
    "# ]\n",
    "class_prior=[0.05]*20\n",
    "\n",
    "# Пострение модели классификации\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(analyzer='char', ngram_range=(2,4))),\n",
    "    ('classifier', MultinomialNB(class_prior=class_prior))\n",
    "])\n",
    "\n",
    "# Обучение модели\n",
    "pipeline.fit(df_train_new['word'], df_train_new['labels'])\n",
    "\n",
    "test_accuracy_on_words = pipeline.score(df_test_new['word'], df_test_new['labels'])\n",
    "test_accuracy_on_texts = pipeline.score(df_test['text'], df_test['labels'])\n",
    "\n",
    "# Оценка качества на тестовом множестве\n",
    "print(f\"Accuracy on Test (word-lang) = {test_accuracy_on_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка качества на тестовом множестве (из первой задачи)\n",
    "print(f\"Accuracy on Test (text-lang) = {test_accuracy_on_texts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Словарь\n",
    "pipeline.named_steps['vectorizer'].vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Классы\n",
    "langs = pipeline.named_steps['classifier'].classes_\n",
    "langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = 'tra'\n",
    "\n",
    "# Вероятности принадлежности классам для некоторого слова\n",
    "probs = pipeline.predict_proba([INPUT,])[0]\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    pd.DataFrame(\n",
    "        data={'prob': probs}, \n",
    "        index=langs)\\\n",
    "    .sort_values(by='prob', ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка динамического распознавания "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_prediction(langs, probs):\n",
    "    \"\"\"\n",
    "    Отображение вероятностей по языкам \n",
    "    в виде датафрейма.\n",
    "    \"\"\"\n",
    "    print(\n",
    "        pd.DataFrame(\n",
    "            data={'prob': probs},\n",
    "            index=langs\n",
    "        )\\\n",
    "        .sort_values('prob', ascending=False)\\\n",
    "        .head(10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ввод текста\n",
    "text_input = widgets.Text()\n",
    "display(text_input)\n",
    "\n",
    "# Вывод результата предсказания\n",
    "output = widgets.Output()\n",
    "display(output)\n",
    "\n",
    "\n",
    "def handle_process_text(sender):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        probs = pipeline.predict_proba([sender.new,])[0]\n",
    "        langs = pipeline.named_steps['classifier'].classes_\n",
    "        display_prediction(langs, probs)\n",
    "\n",
    "\n",
    "# Отслеживание ввода\n",
    "text_input.observe(handle_process_text, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
