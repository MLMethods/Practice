{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Распознавание языка текста\n",
    "\n",
    "<hr>\n",
    "\n",
    "С.Ю. Папулин (papulin.study@yandex.ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Содержание\n",
    "\n",
    "- [Статический текст](#Статический-текст)\n",
    "- [Динамический текст](#Динамический-текст)\n",
    "    - [Построение модели](#Построение-модели)\n",
    "    - [Проверка динамического распознавания](#Проверка-динамического-распознавания)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключение библиотек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../lib/\")\n",
    "from datasets import fetch_20languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Статический текст"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Набор данных](https://huggingface.co/datasets/papluca/language-identification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "dataset = fetch_20languages(return_X_y=True)\n",
    "\n",
    "# Вывод описания\n",
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.data['train']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../data/lang_detector/train.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество текстов по каждому классу\n",
    "df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Среднее количество символов в текстах по каждому классу\n",
    "df.groupby('labels').agg(\n",
    "    lambda group: group['text'].str.len().mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(df['text'], df['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/lang_detector/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(df_test['text'], df_test['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Динамический текст"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Исходные данные\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаблон для делителя строки на слова\n",
    "COMPILER = re.compile(\"\\W+\", re.UNICODE)\n",
    "\n",
    "\n",
    "def split_sentence(lang, text):\n",
    "    s = list()\n",
    "    for word in set(COMPILER.split(text)):\n",
    "        if word:\n",
    "            s.append((lang, word))\n",
    "    return s\n",
    "\n",
    "\n",
    "# Формирование списка пар язык-слово\n",
    "data = list()\n",
    "for i, row in df.iterrows():\n",
    "    data += split_sentence(row['labels'], row['text'])\n",
    "    \n",
    "    \n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формивание датафрейма язык-слово и удаление повторений\n",
    "df_new = pd.DataFrame(data=data, columns=['labels', 'word']).drop_duplicates()\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = 'обуч'\n",
    "\n",
    "print(\n",
    "    df_new[df_new['word'].str.contains(INPUT)]\\\n",
    "        .groupby('labels')\\\n",
    "        .count().T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Априорные вероятности классов\n",
    "# class_prior=[\n",
    "#     0.04, 0.04, 0.05, 0.05, 0.1, 0.05, 0.05, 0.04, 0.05, 0.05,\n",
    "#     0.05, 0.05, 0.05, 0.05, 0.05, 0.04, 0.04, 0.05, 0.05, 0.05\n",
    "# ]\n",
    "class_prior=[0.05]*20\n",
    "\n",
    "# Пострение модели классификации\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(analyzer='char', ngram_range=(2,4))),\n",
    "    ('classifier', MultinomialNB(class_prior=class_prior))\n",
    "])\n",
    "\n",
    "# Обучение модели\n",
    "pipeline.fit(df_new['word'], df_new['labels'])\n",
    "\n",
    "print(\n",
    "    # Оценка качества на тестовом множестве (из первой задачи)\n",
    "    f\"Accuracy = { pipeline.score(df_test['text'], df_test['labels']) }\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline.named_steps['vectorizer'].vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Классы\n",
    "langs = pipeline.named_steps['classifier'].classes_\n",
    "langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = 'обуч'\n",
    "\n",
    "# Вероятности принадлежности классам для некоторого слова\n",
    "probs = pipeline.predict_proba([INPUT,])[0]\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка динамического распознавания "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_prediction(langs, probs):\n",
    "    \"\"\"\n",
    "    Отображение вероятностей по языкам \n",
    "    в виде датафрейма.\n",
    "    \"\"\"\n",
    "    print(\n",
    "        pd.DataFrame(\n",
    "            data=zip(langs, probs),\n",
    "            columns=['lang', 'prob']\n",
    "        )\\\n",
    "        .sort_values('prob', ascending=0)\\\n",
    "        .head(10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ввод текста\n",
    "text_input = widgets.Text()\n",
    "display(text_input)\n",
    "\n",
    "# Вывод результата предсказания\n",
    "output = widgets.Output()\n",
    "display(output)\n",
    "\n",
    "\n",
    "def handle_process_text(sender):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        probs = pipeline.predict_proba([sender.new,])[0]\n",
    "        langs = pipeline.named_steps['classifier'].classes_\n",
    "        display_prediction(langs, probs)\n",
    "\n",
    "\n",
    "# Отслеживание ввода\n",
    "text_input.observe(handle_process_text, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
