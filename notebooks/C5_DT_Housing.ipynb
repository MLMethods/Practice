{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# СЕМИНАР. Деревья решений для задачи регрессии\n",
    "\n",
    "---\n",
    "\n",
    "Папулин С.Ю. (papulin.study@yandex.ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "1. [Загрузка набора данных](#Загрузка-набора-данных)\n",
    "2. [Дерево решений](#Дерево-решений)\n",
    "3. [Выбор лучших параметров](#Выбор-лучших-параметров)\n",
    "4. [Ансамбли деревьев](#Ансамбли-деревьев)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    train_test_split, \n",
    "    GridSearchCV, \n",
    "    KFold, \n",
    "    cross_validate\n",
    ")\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor#, plot_tree\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    BaggingRegressor,\n",
    "    RandomForestRegressor,\n",
    "    ExtraTreesRegressor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка набора данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные были использованы в работе: Harrison, D. and Rubinfeld, D.L. \"Hedonic prices and the demand for clean air\", J. Environ. Economics & Management, vol.5, 81-102, 1978."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные на основе: 1970 U.S. Census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки:\n",
    "1. `CRIM`: per capita crime rate by town\n",
    "2. `ZN`: proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "3. `INDUS`: proportion of non-retail business acres per town\n",
    "4. `CHAS`: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "5. `NOX`: nitric oxides concentration (parts per 10 million)\n",
    "6. `RM`: average number of rooms per dwelling\n",
    "7. `AGE`: proportion of owner-occupied units built prior to 1940\n",
    "8. `DIS`: weighted distances to five Boston employment centres\n",
    "9. `RAD`: index of accessibility to radial highways\n",
    "10. `TAX`: full-value property-tax rate per \\$10.000\n",
    "11. `PTRATIO`: pupil-teacher ratio by town\n",
    "12. `B`: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "13. `LSTAT`: % lower status of the population\n",
    "14. `MEDV`: Median value of owner-occupied homes in \\$1000’s\n",
    "\n",
    "\n",
    "Категории признаков:\n",
    "\n",
    "1. Характеристики жилья: `RM` и `AGE`\n",
    "2. Район: `CRIM`, `ZN`, `INDUS`, `CHAS`, `TAX`, `PTRATIO`, `B` и `LSTAT`\n",
    "3. Доступность: `DIS` и `RAD`\n",
    "4. Загрязненность: `NOX`\n",
    "\n",
    "Целевое значение: `MEDV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = \"../data/boston-house-price.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLMNS = [\n",
    "    \"CRIM\",\n",
    "    \"ZN\",\n",
    "    \"INDUS\",\n",
    "    \"CHAS\",\n",
    "    \"NOX\",\n",
    "    \"RM\",\n",
    "    \"AGE\",\n",
    "    \"DIS\",\n",
    "    \"RAD\",\n",
    "    \"TAX\",\n",
    "    \"PTRATIO\",\n",
    "    \"B\",\n",
    "    \"LSTAT\",\n",
    "    \"MEDV\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house = pd.read_csv(DATA_FILE, header=None, names=CLMNS)\n",
    "df_house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формирование матрицы признаков и целевого значения\n",
    "\n",
    "# Столбец целевого значения\n",
    "target_clmn = \"MEDV\"\n",
    "\n",
    "# Столбцы признаков\n",
    "all_feature_clmns = CLMNS.copy()\n",
    "all_feature_clmns.remove(target_clmn)\n",
    "\n",
    "# Матрица признаков и вектор целевых значений\n",
    "X = df_house[all_feature_clmns].to_numpy()\n",
    "y = df_house[target_clmn].to_numpy()\n",
    "\n",
    "# X, y = shuffle(X, y, random_state=RANDOM_STATE)\n",
    "\n",
    "# Разбиение исходных данных на обучающее и тестовое множества\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение\n",
    "tick = time.time()\n",
    "dtr_model = DecisionTreeRegressor(criterion=\"mse\", max_depth=3, random_state=RANDOM_STATE)\n",
    "dtr_model.fit(X_train, y_train)\n",
    "print(\"Time =\", time.time()-tick)\n",
    "\n",
    "\n",
    "y_test__pred = dtr_model.predict(X_test)\n",
    "\n",
    "# Проверка на тестовом подмножестве\n",
    "r2_dtr_model = dtr_model.score(X_test, y_test)\n",
    "mse_dtr_model = mean_squared_error(y_test, y_test__pred)\n",
    "mae_dtr_model = mean_absolute_error(y_test, y_test__pred)\n",
    "\n",
    "print(\"R^2 =\", r2_dtr_model)\n",
    "print(\"MSE =\", mse_dtr_model)\n",
    "print(\"MAE =\", mae_dtr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отображение дерева решений\n",
    "plt.figure(figsize=[14, 4])\n",
    "plot_tree(dtr_model, filled=True, feature_names=all_feature_clmns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = dtr_model.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(feature_importances, feature_names, figsize=[4,6]):\n",
    "    \n",
    "    x_num = len(feature_importances)\n",
    "    y_num = len(feature_names)\n",
    "    \n",
    "    if x_num != y_num:\n",
    "        raise ValueError(\"Vectors have different dimensions.\")\n",
    "    \n",
    "    x = range(x_num)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.barh(x, width=feature_importances[::-1], height=0.5, color=\"green\")\n",
    "    plt.yticks(x, feature_names[::-1], rotation=\"horizontal\")\n",
    "    plt.tick_params(labelbottom=\"on\", labeltop=\"on\")\n",
    "    plt.xlabel(\"Feature Importances\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_prediction_vs_true(y_true, y_pred):\n",
    "    plt.scatter(y_pred, y_true, color=\"slategrey\")\n",
    "    xlim = plt.gca().get_xlim() \n",
    "    plt.plot(xlim, xlim, '--', color=\"grey\")\n",
    "    plt.xlim(xlim) \n",
    "    plt.xlabel(\"$\\\\bar{y}$\")\n",
    "    plt.ylabel(\"$y$\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(feature_importances, all_feature_clmns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_vs_true(y_test, y_test__pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор лучших параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLITS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация делителя для кросс-валидации\n",
    "kf = KFold(n_splits=SPLITS, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры дерева решения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сетка параметров\n",
    "parameters = {\n",
    "    \"max_depth\": np.arange(5, 21, 5),\n",
    "    \"min_samples_leaf\": np.arange(100, 4, -10)\n",
    "}\n",
    "\n",
    "model = DecisionTreeRegressor(criterion=\"mse\")\n",
    "\n",
    "# Обучение\n",
    "tick = time.time()\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=parameters, cv=kf)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Time =\", time.time()-tick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test__pred = best_model.predict(X_test)\n",
    "\n",
    "# Проверка на тестовом подмножестве\n",
    "r2_dtr_model = best_model.score(X_test, y_test)\n",
    "mse_dtr_model = mean_squared_error(y_test, y_test__pred)\n",
    "mae_dtr_model = mean_absolute_error(y_test, y_test__pred)\n",
    "\n",
    "print(\"R^2 =\", r2_dtr_model)\n",
    "print(\"MSE =\", mse_dtr_model)\n",
    "print(\"MAE =\", mae_dtr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(best_model.feature_importances_, all_feature_clmns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_vs_true(y_test, y_test__pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подрезка дерева решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: control complexity parameter ccp_alpha that was introduced in version 0.22 of sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ансамбли деревьев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бэггинг с отложенной выборкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TREES = 100\n",
    "\n",
    "model = DecisionTreeRegressor(criterion=\"mse\")\n",
    "\n",
    "# Обучение\n",
    "tick = time.time()\n",
    "bagging = BaggingRegressor(base_estimator=model, n_estimators=NUM_TREES, max_samples=1.0, \n",
    "                                  max_features=1.0, bootstrap=True, bootstrap_features=False, \n",
    "                                  oob_score=False, random_state=RANDOM_STATE)\n",
    "bagging.fit(X_train, y_train)\n",
    "print(\"Time =\", time.time()-tick)\n",
    "\n",
    "y_test__pred = bagging.predict(X_test)\n",
    "\n",
    "# Проверка на тестовом подмножестве\n",
    "r2_bagging = bagging.score(X_test, y_test)\n",
    "mse_bagging = mean_squared_error(y_test, y_test__pred)\n",
    "mae_bagging = mean_absolute_error(y_test, y_test__pred)\n",
    "\n",
    "print(\"MSE =\", mse_bagging)\n",
    "print(\"R^2 =\", r2_bagging)\n",
    "print(\"MAE =\", mae_bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_vs_true(y_test, y_test__pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бэггинг с кросс-валидацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLITS = 5\n",
    "\n",
    "kf = KFold(n_splits=SPLITS, shuffle=False)\n",
    "\n",
    "model = BaggingRegressor(\n",
    "        base_estimator=model, \n",
    "        n_estimators=NUM_TREES, \n",
    "        random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "tick = time.time()\n",
    "scores = cross_validate(model, X, y, cv=kf, \n",
    "                        return_train_score=True,\n",
    "                        scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"])\n",
    "dt = time.time()-tick\n",
    "\n",
    "mse_avg = np.abs(scores[\"test_neg_mean_squared_error\"].mean())\n",
    "mse_std = scores[\"test_neg_mean_squared_error\"].std()\n",
    "r2_avg = scores[\"test_r2\"].mean()\n",
    "r2_std = scores[\"test_r2\"].std()\n",
    "mae_avg = np.abs(scores[\"test_neg_mean_absolute_error\"].mean())\n",
    "mae_std = scores[\"test_neg_mean_absolute_error\"].std()\n",
    "\n",
    "print(\"Time \\t= {:0.5f}s\".format(dt))\n",
    "print(\"CI MSE \\t= {:0.3f} +/- {:0.3f}\".format(mse_avg, mse_std * 2.0))\n",
    "print(\"CI R^2 \\t= {:0.3f} +/- {:0.3f}\".format(r2_avg, r2_std * 2.0))\n",
    "print(\"CI MAE \\t= {:0.3f} +/- {:0.3f}\\n\".format(mae_avg, mae_std * 2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор модели/алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "#     BaggingRegressor(\n",
    "#         base_estimator=model, \n",
    "#         n_estimators=NUM_TREES, \n",
    "#         random_state=RANDOM_STATE\n",
    "#     ),\n",
    "    RandomForestRegressor(\n",
    "        n_estimators=NUM_TREES, \n",
    "        criterion=\"mse\", \n",
    "        max_features=\"sqrt\",  \n",
    "        random_state=RANDOM_STATE\n",
    "    ),\n",
    "    ExtraTreesRegressor(\n",
    "        n_estimators=NUM_TREES, \n",
    "        criterion=\"mse\", \n",
    "        bootstrap=True, \n",
    "        max_features=\"sqrt\",\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "min_mse = float(\"inf\")\n",
    "best_model = None\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    tick = time.time()\n",
    "    scores = cross_validate(model, X_train, y_train, cv=kf, \n",
    "                            return_train_score=True, \n",
    "                            scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"r2\"])\n",
    "    dt = time.time()-tick\n",
    "    \n",
    "    mse_avg = np.abs(scores[\"test_neg_mean_squared_error\"].mean())\n",
    "    mse_std = scores[\"test_neg_mean_squared_error\"].std()\n",
    "    r2_avg = scores[\"test_r2\"].mean()\n",
    "    r2_std = scores[\"test_r2\"].std()\n",
    "    mae_avg = np.abs(scores[\"test_neg_mean_absolute_error\"].mean())\n",
    "    mae_std = scores[\"test_neg_mean_absolute_error\"].std()\n",
    "    \n",
    "    if mse_avg < min_mse:\n",
    "        min_mse = mse_avg\n",
    "        best_model = model\n",
    "    \n",
    "    print(\"{}\".format(model.__class__.__name__))\n",
    "    print(\"\\tTime \\t= {:0.5f}s\".format(dt))\n",
    "    print(\"\\tCI MSE \\t= {:0.3f} +/- {:0.3f}\".format(mse_avg, mse_std * 2.0))\n",
    "    print(\"\\tCI R^2 \\t= {:0.3f} +/- {:0.3f}\".format(r2_avg, r2_std * 2.0))\n",
    "    print(\"\\tCI MAE \\t= {:0.3f} +/- {:0.3f}\\n\".format(mae_avg, mae_std * 2.0))\n",
    "    \n",
    "\n",
    "print(\"Best model:\", best_model.__class__.__name__)\n",
    "\n",
    "# Повторное обучение   \n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "if hasattr(best_model, \"feature_importances_\"):\n",
    "    print(\"Feature Importances:\")\n",
    "    plot_feature_importances(best_model.feature_importances_, all_feature_clmns)\n",
    "\n",
    "y_test__pred = best_model.predict(X_test)\n",
    "\n",
    "# Проверка на тестовом подмножестве\n",
    "r2_best_model = best_model.score(X_test, y_test)\n",
    "mse_best_model = mean_squared_error(y_test, y_test__pred)\n",
    "mae_best_model = mean_absolute_error(y_test, y_test__pred)\n",
    "\n",
    "print(\"Test set:\")\n",
    "print(\"\\tR^2 =\", r2_best_model)\n",
    "print(\"\\tMSE =\", mse_best_model)\n",
    "print(\"\\tMAE =\", mae_best_model)\n",
    "\n",
    "plot_prediction_vs_true(y_test, y_test__pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use gridsearchcv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
